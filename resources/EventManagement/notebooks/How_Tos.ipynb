{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# To get multiple outputs from one code cell (without using print()):\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = 'all'\n",
    "\n",
    "from IPython import get_ipython\n",
    "from IPython.display import HTML, Markdown, Image, Audio\n",
    "\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# For documenting the current environment:\n",
    "def sys_info():\n",
    "    frmt = '\\nPython ver: {}\\nPython env: {}\\n'\n",
    "    frmt += 'OS:         {}\\nCurrent dir: {}\\n'\n",
    "    print(frmt.format(sys.version, \n",
    "                      Path(sys.prefix).name,\n",
    "                      sys.platform,\n",
    "                      Path.cwd()))\n",
    "\n",
    "# For enabling imports from current project code:\n",
    "def add_to_sys_path(this_path, up=False):\n",
    "    \"\"\"\n",
    "    Prepend this_path to sys.path.\n",
    "    If up=True, path refers to parent folder (1 level up).\n",
    "    \"\"\"\n",
    "    newp = Path(this_path).as_posix() # no str method (?)\n",
    "    if up:\n",
    "        newp = Path(this_path).parent.as_posix()\n",
    "\n",
    "    msg = F'Path already in sys.path: {newp}'\n",
    "    if newp not in sys.path:\n",
    "        sys.path.insert(1, newp)\n",
    "        msg = F'Path added to sys.path: {newp}'\n",
    "    print(msg)\n",
    "\n",
    "add_to_sys_path(Path.cwd(), up=True)\n",
    "\n",
    "# For py modules/methods discovery:\n",
    "def filter_dir(mdl, filter_str=None, start_with_str='_', exclude=True):\n",
    "    \"\"\"Filter dir(mdl) for method discovery.\n",
    "       Input:\n",
    "       :param mdl (object): module, optionally with submodule path(s), e.g. mdl.submdl1.submdl2.\n",
    "       :param filter_str (str, None): filter all method names containing that string.\n",
    "       :param start_with_str (str, '_'), exclude (bool, True): start_with_str and exclude work \n",
    "              together to perform search on non-dunder methods (default).\n",
    "       Example:\n",
    "       >filter_dir(re) # lists the public methods of the re module.\n",
    "    \"\"\"\n",
    "    search_dir = [d for d in dir(mdl) if not d.startswith(start_with_str) == exclude]\n",
    "    if filter_str is None:\n",
    "        return search_dir\n",
    "    else:\n",
    "        filter_str = filter_str.lower()\n",
    "        return [d for d in search_dir if d.lower().find(filter_str) != -1]\n",
    "\n",
    "# To create often-used subfolders:\n",
    "def get_project_dirs(which=['data', 'images'],\n",
    "                     use_parent=True):\n",
    "    '''Create folder(s) named in `which` at the ipynb parent level.'''\n",
    "    if use_parent:\n",
    "        dir_fn = Path.cwd().parent.joinpath\n",
    "    else:\n",
    "        dir_fn = Path.cwd().joinpath\n",
    "        \n",
    "    dir_lst = []    \n",
    "    for d in which:\n",
    "        DIR = dir_fn(d)\n",
    "        if not DIR.exists():\n",
    "            Path.mkdir(DIR)\n",
    "        dir_lst.append(DIR)\n",
    "    return dir_lst\n",
    "\n",
    "DIR_DATA, DIR_IMG = get_project_dirs()\n",
    "\n",
    "import pandas as pd\n",
    "#pd.set_option(\"display.max_colwidth\", 200)\n",
    "from pprint import pprint as pp\n",
    "\n",
    "    \n",
    "def new_section(title='New section'):\n",
    "    style = \"text-align:center;background:#c2d3ef;padding:16px;color:#ffffff;font-size:2em;width:98%\"\n",
    "    div = f'<div style=\"{style}\">{title}</div>'\n",
    "    #return HTML('<div style=\"{}\">{}</div>'.format(style, title))\n",
    "    return get_ipython().set_next_input(div, 'markdown')\n",
    "\n",
    "\n",
    "# For documenting the current environment:\n",
    "def show_versions():\n",
    "    txt = '<pre><br>'\n",
    "    txt += F'Python:\\t\\t{sys.version}<br>'\n",
    "    txt += F'Python env:\\t{Path(sys.prefix).name}<br>'\n",
    "    txt += F'Numpy:\\t\\t{np.__version__}<br>'\n",
    "    txt += F'Scipy:\\t\\t{sp.__version__}<br>'\n",
    "    txt += F'Pandas:\\t\\t{pd.__version__}<br>'\n",
    "    txt += F'Matplotlib:\\t{mpl.__version__}<br>'\n",
    "    txt += F'Currrent dir: {Path.cwd()}'\n",
    "    txt += '</pre>'\n",
    "    div = f\"\"\"<div class=\"alert alert-info\"><b>Versions:</b><br>{txt}</div>\"\"\"\n",
    "    return HTML(div)\n",
    "\n",
    "\n",
    "# autoreload extension\n",
    "if 'autoreload' not in get_ipython().extension_manager.loaded:\n",
    "    get_ipython().run_line_magic('load_ext', 'autoreload')\n",
    "\n",
    "%autoreload 2\n",
    "\n",
    "#..................\n",
    "sys_info()\n",
    "\n",
    "no_wmark = False\n",
    "try:\n",
    "    %load_ext watermark\n",
    "    %watermark\n",
    "except ModuleNotFoundError:\n",
    "    no_wmark = True\n",
    "\n",
    "if no_wmark:\n",
    "    show_versions()\n",
    "else:\n",
    "    %watermark -iv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "---\n",
    "# How To Amend Text Processing Files (Corrections, People, Names, Places)  \n",
    "This step is at the moment not incorporated into the GUI EDIT page.  \n",
    "\n",
    "## Use Case:\n",
    "You have just launched an Editing session (via ManageGUI.ipynb) and you realize that some words/phrases that need some correcting are occurring with high frequency in the event transcript.  \n",
    "Even if you have the Grammarly extension installed in your browser, the task of applying the suggested corrections - if they exist! - it quite tedious.   \n",
    "This **How To** shows you how to augment any of the text processing files and re-run the transcription.\n",
    "\n",
    "## 'Correctability' Criteria:  \n",
    "\n",
    "### Proper casing:  \n",
    "* Titlecasing: some words/phrases should be titlecased but were skipped because they are not found in the People, Names, or Places csv files.  \n",
    "* Uppercasing: some acronyms/company names should be uppercased (e.g.: AMD, SMTP, SAP).  \n",
    "\n",
    "### Corrections:  \n",
    "* Errors from auto-generated captions. Examples: Reshama's name occurs in 7 flavors (all wrong); 'marco guerrelli' or 'marco gorilla' -> 'Marco Gorelli'; 'pi ladies' -> 'PyLadies'\n",
    "* Special casing: e.g.: 'macbook' -> 'MacBook'; 'iot' -> 'IoT'.\n",
    "* Speech utterances that need removing: e.g. 'uh'.\n",
    "\n",
    "## Steps:\n",
    "1. Read the transcript and keep a record of the frequently occurring words.\n",
    "2. Gather the high-frequency terms that need amending into categories: People (first, last, or full names), Names (organizations/institutions, companies, software & libraries), Places (geographic, street names), or Corrections.\n",
    "3. Continue by running the following cells using the data you want to add.\n",
    "4. Redo the text processing.\n",
    "\n",
    "\n",
    "## Functions: `EventTranscription.update_substitution_file` or `EventTranscription.add_corrections`\n",
    "1. `.update_substitution_file`\n",
    "This function takes two paramters: `which`: to indicate which file to augment (people, names, places, or upper), and `user_list`: the terms to add.  \n",
    "Only new entries are added.  \n",
    "2. `.add_corrections` \n",
    "This function accepts a list of tuples, e.g.: correction_lst = [('west mckinney', 'Wes McKinney'), ('rashama', 'Reshama')]\n",
    "\n",
    "### TODO: amend `EventTranscription.add_corrections` to only add new entries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from manage import (EventMeta as Meta,\n",
    "                    EventTranscription as TRX)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add to Corrections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtain the corrections as a dict:\n",
    "\n",
    "corrections = TRX.get_corrections_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run a check to avoid duplication: an output ending with '-1' indicates the entry does not exist\n",
    "\n",
    "correction_lst = [('west mckinney', 'Wes McKinney'),\n",
    "                  ('rashama', 'Reshama'),\n",
    "                  ('university of edinburg', 'University of Edinburg'),\n",
    "                  ('washington dc', 'Washington DC')\n",
    "                  ('dummy', 'enTRY')]\n",
    "\n",
    "check = TRX.check_corrections(corrections, correction_lst)\n",
    "if check == -1 * len(correction_lst):\n",
    "    print(\"OK to include all.\")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove any exisitng entry if previous check did not print \"OK to include all.\", then update:\n",
    "\n",
    "corrections = TRX.add_corrections(correction_lst)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add Names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_names = ['matplotlib', 'seaborn','plotly','fibonacci', 'wikipedia', 'markdown','windows', ]\n",
    "\n",
    "# Update:\n",
    "TRX.update_substitution_file(which='names', user_list=new_names)\n",
    "\n",
    "# Optional: recall the list to check:\n",
    "names_list = TRX.readcsv(TRX.names_file).names.tolist()\n",
    "\n",
    "'fibonacci' in names_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add Places"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_terms = ['columbia university']\n",
    "TRX.update_substitution_file(which='places', user_list=new_terms)\n",
    "\n",
    "#places_list = TRX.readcsv(TRX.places_file).places.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add People"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_terms = ['melissa','brian', 'jeff', 'jeff ryback', 'marco', 'marco gorelli']\n",
    "\n",
    "TRX.update_substitution_file(which='people', user_list=new_terms)\n",
    "#people_list = TRX.readcsv(TRX.people_file).people.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add Upper terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_terms = ['nyu']\n",
    "\n",
    "TRX.update_substitution_file(which='upper', user_list=new_terms)\n",
    "#upper_list = TRX.readcsv(TRX.upper_file).upper.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Redo initial transcript"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instantiate the event class for the event you want re-processed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr = Meta.TranscriptMeta(20, 2020)  # id, year\n",
    "\n",
    "# This is how you access the event data:\n",
    "tr.event_dict['transcript_md']\n",
    "tr.event_dict['has_transcript']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Case 1:  Redo if any of the Corrections, People, Names, Places, or Upper terms files was updated.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Re-process the captions and reinsert into transcript md file:\n",
    "\n",
    "tr.redo_initial_transcript()\n",
    "tr.insert_md_transcript()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Case 2:  Redo if you want to change the wrap width or the time chuncking\n",
    "To change these formatting parameters, assign new values to `tr.new_minutes_mark` and `tr.new_wrap_width`.  <br>\n",
    "Note:  Default values in YTVAudio class are 4 (minutes) and 120 (characters).  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr.new_minutes_mark = 5\n",
    "tr.new_wrap_width = 100\n",
    "  \n",
    "# Re-process the captions and reinsert into transcript md file:\n",
    "tr.redo_initial_transcript()\n",
    "tr.insert_md_transcript()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize: Print text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tr.event_dict['formatted_transcript'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize: Render updated file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mdfile = Meta.REPO_PATH.joinpath(tr.event_dict['year'], tr.event_dict['transcript_md'])\n",
    "Markdown(mdfile)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
