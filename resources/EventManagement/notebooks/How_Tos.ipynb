{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Run the first cell! (collapsed in JuyterLab)_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path added to sys.path: C:/Users/catch/Documents/GitHub/DU-event-transcript-demo/resources/EventManagement\n",
      "\n",
      "Python ver: 3.7.6 | packaged by conda-forge | (default, Jun  1 2020, 18:11:50) [MSC v.1916 64 bit (AMD64)]\n",
      "Python env: p37\n",
      "OS:         win32\n",
      "Current dir: C:\\Users\\catch\\Documents\\GitHub\\DU-event-transcript-demo\\resources\\EventManagement\\notebooks\n",
      "\n",
      "2021-01-28T14:46:56-05:00\n",
      "\n",
      "CPython 3.7.6\n",
      "IPython 7.16.1\n",
      "\n",
      "compiler   : MSC v.1916 64 bit (AMD64)\n",
      "system     : Windows\n",
      "release    : 10\n",
      "machine    : AMD64\n",
      "processor  : Intel64 Family 6 Model 142 Stepping 10, GenuineIntel\n",
      "CPU cores  : 8\n",
      "interpreter: 64bit\n",
      "pandas 1.0.5\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# To get multiple outputs from one code cell (without using print()):\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = 'all'\n",
    "\n",
    "from IPython import get_ipython\n",
    "from IPython.display import HTML, Markdown, Image, Audio\n",
    "\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# For documenting the current environment:\n",
    "def sys_info():\n",
    "    frmt = '\\nPython ver: {}\\nPython env: {}\\n'\n",
    "    frmt += 'OS:         {}\\nCurrent dir: {}\\n'\n",
    "    print(frmt.format(sys.version, \n",
    "                      Path(sys.prefix).name,\n",
    "                      sys.platform,\n",
    "                      Path.cwd()))\n",
    "\n",
    "# For enabling imports from current project code:\n",
    "def add_to_sys_path(this_path, up=False):\n",
    "    \"\"\"\n",
    "    Prepend this_path to sys.path.\n",
    "    If up=True, path refers to parent folder (1 level up).\n",
    "    \"\"\"\n",
    "    newp = Path(this_path).as_posix() # no str method (?)\n",
    "    if up:\n",
    "        newp = Path(this_path).parent.as_posix()\n",
    "\n",
    "    msg = F'Path already in sys.path: {newp}'\n",
    "    if newp not in sys.path:\n",
    "        sys.path.insert(1, newp)\n",
    "        msg = F'Path added to sys.path: {newp}'\n",
    "    print(msg)\n",
    "\n",
    "add_to_sys_path(Path.cwd(), up=True)\n",
    "\n",
    "# For py modules/methods discovery:\n",
    "def filter_dir(mdl, filter_str=None, start_with_str='_', exclude=True):\n",
    "    \"\"\"Filter dir(mdl) for method discovery.\n",
    "       Input:\n",
    "       :param mdl (object): module, optionally with submodule path(s), e.g. mdl.submdl1.submdl2.\n",
    "       :param filter_str (str, None): filter all method names containing that string.\n",
    "       :param start_with_str (str, '_'), exclude (bool, True): start_with_str and exclude work \n",
    "              together to perform search on non-dunder methods (default).\n",
    "       Example:\n",
    "       >filter_dir(re) # lists the public methods of the re module.\n",
    "    \"\"\"\n",
    "    search_dir = [d for d in dir(mdl) if not d.startswith(start_with_str) == exclude]\n",
    "    if filter_str is None:\n",
    "        return search_dir\n",
    "    else:\n",
    "        filter_str = filter_str.lower()\n",
    "        return [d for d in search_dir if d.lower().find(filter_str) != -1]\n",
    "\n",
    "# To create often-used subfolders:\n",
    "def get_project_dirs(which=['data', 'images'],\n",
    "                     use_parent=True):\n",
    "    '''Create folder(s) named in `which` at the ipynb parent level.'''\n",
    "    if use_parent:\n",
    "        dir_fn = Path.cwd().parent.joinpath\n",
    "    else:\n",
    "        dir_fn = Path.cwd().joinpath\n",
    "        \n",
    "    dir_lst = []    \n",
    "    for d in which:\n",
    "        DIR = dir_fn(d)\n",
    "        if not DIR.exists():\n",
    "            Path.mkdir(DIR)\n",
    "        dir_lst.append(DIR)\n",
    "    return dir_lst\n",
    "\n",
    "DIR_DATA, DIR_IMG = get_project_dirs()\n",
    "\n",
    "import pandas as pd\n",
    "#pd.set_option(\"display.max_colwidth\", 200)\n",
    "from pprint import pprint as pp\n",
    "\n",
    "    \n",
    "def new_section(title='New section'):\n",
    "    style = \"text-align:center;background:#c2d3ef;padding:16px;color:#ffffff;font-size:2em;width:98%\"\n",
    "    div = f'<div style=\"{style}\">{title}</div>'\n",
    "    #return HTML('<div style=\"{}\">{}</div>'.format(style, title))\n",
    "    return get_ipython().set_next_input(div, 'markdown')\n",
    "\n",
    "\n",
    "# For documenting the current environment:\n",
    "def show_versions():\n",
    "    txt = '<pre><br>'\n",
    "    txt += F'Python:\\t\\t{sys.version}<br>'\n",
    "    txt += F'Python env:\\t{Path(sys.prefix).name}<br>'\n",
    "    txt += F'Numpy:\\t\\t{np.__version__}<br>'\n",
    "    txt += F'Scipy:\\t\\t{sp.__version__}<br>'\n",
    "    txt += F'Pandas:\\t\\t{pd.__version__}<br>'\n",
    "    txt += F'Matplotlib:\\t{mpl.__version__}<br>'\n",
    "    txt += F'Currrent dir: {Path.cwd()}'\n",
    "    txt += '</pre>'\n",
    "    div = f\"\"\"<div class=\"alert alert-info\"><b>Versions:</b><br>{txt}</div>\"\"\"\n",
    "    return HTML(div)\n",
    "\n",
    "\n",
    "# autoreload extension\n",
    "if 'autoreload' not in get_ipython().extension_manager.loaded:\n",
    "    get_ipython().run_line_magic('load_ext', 'autoreload')\n",
    "\n",
    "%autoreload 2\n",
    "\n",
    "#..................\n",
    "sys_info()\n",
    "\n",
    "no_wmark = False\n",
    "try:\n",
    "    %load_ext watermark\n",
    "    %watermark\n",
    "except ModuleNotFoundError:\n",
    "    no_wmark = True\n",
    "\n",
    "if no_wmark:\n",
    "    show_versions()\n",
    "else:\n",
    "    %watermark -iv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "---\n",
    "# List of How-Tos:  \n",
    "\n",
    "0. [Import required project modules](#0)\n",
    "1. [How To Amend Text Processing Files (Corrections, People, Names, Places, Upper)](#01)\n",
    " * [Add to Corrections](#01.1)\n",
    " * [Add to Other Replacement Files](#01.2)\n",
    "2. [How To Redo the Initial Transcript](#02)\n",
    " * [Instantiate the event class for the event you want re-processed](#02.0)\n",
    " * [Redo if any of the text processing files was updated](#02.1)\n",
    " * [Redo if you want different wrap-width or time-chuncking values](02.2)\n",
    " * [Visualize](#02.3)\n",
    "3. [How To Download the Audio File](#03)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "---\n",
    "<a id='0'></a>\n",
    "# 0. Import required project modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from manage import (EventMeta as Meta,\n",
    "                    EventTranscription as TRX)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "---\n",
    "<a id='01'></a>\n",
    "# 1. How To Amend Text Processing Files (Corrections, People, Names, Places, Upper)  \n",
    "#### Note 1:  This step is at the moment not incorporated into the GUI EDIT page.\n",
    "#### Note 2: At the moment the `EventTranscription.clean_text` function _removes_ two speech utterrances: ('um' and 'uh'). You would need to place a PR to add other ones.\n",
    "\n",
    "\n",
    "### What do this files do & what are their contents?\n",
    "* **People, Names, Places** csv files:\n",
    " - List of lowercase words or phrases for _conversion_ to titlecase, e.g. 'oxford university' -> 'Oxford University'\n",
    "* **Upper** csv file:\n",
    " - List of lowercase words or phrases for _conversion_ to uppercase, e.g. 'aws' -> 'AWS'\n",
    "* **Corrections** csv file:\n",
    " - List of tuples for _replacement_, e.g. ('pi ladies', 'PyLadies'), (\"miriam's webster's\", 'Merriam-Webster')\n",
    "* **File paths**: Their paths are referenced in the `EventTranscription` module:  \n",
    "```\n",
    "people_file = Meta.DIR_DATA.joinpath('title_people.csv')\n",
    "names_file = Meta.DIR_DATA.joinpath('title_names.csv')\n",
    "places_file = Meta.DIR_DATA.joinpath('title_places.csv')\n",
    "upper_file = Meta.DIR_DATA.joinpath('upper_terms.csv')\n",
    "# Replacement pairs: (from , to); for special str & those mangled by Google's autocaptioning:\n",
    "corrections_file = Meta.DIR_DATA.joinpath('corrections.csv')\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use Case:\n",
    "You have just launched an Editing session (via ManageGUI.ipynb) and you realize that some words/phrases that need some correcting are occurring with high frequency in the event transcript.  \n",
    "Even if you have the Grammarly extension installed in your browser, the task of applying the suggested corrections - if they exist! - it quite tedious.   \n",
    "This **How To** shows you how to augment any of the text processing files and re-run the transcription.\n",
    "\n",
    "## 'Correctability' Criteria:  \n",
    "\n",
    "### Proper casing:  \n",
    "* Titlecasing: some words/phrases should be titlecased but were skipped because they are not found in the People, Names, or Places csv files.  \n",
    "* Uppercasing: some acronyms/company names should be uppercased (e.g.: AMD, SMTP, SAP).  \n",
    "\n",
    "### Corrections:  \n",
    "* Errors from auto-generated captions. Examples: Reshama's name occurs in 7 flavors (all wrong); 'marco guerrelli' or 'marco gorilla' -> 'Marco Gorelli'; 'pi ladies' -> 'PyLadies'\n",
    "* Special casing: e.g.: 'macbook' -> 'MacBook'; 'iot' -> 'IoT'.\n",
    "\n",
    "## Steps:\n",
    "1. Read the transcript and keep a record of the frequently occurring words.\n",
    "2. Gather the high-frequency terms that need amending into categories: People (first, last, or full names), Names (organizations/institutions, companies, software & libraries), Places (geographic, street names), or Corrections.\n",
    "3. Continue by running the following cells using the data you want to add.\n",
    "4. Redo the text processing.\n",
    "\n",
    "\n",
    "## Functions: `EventTranscription.update_conversion_file` or `EventTranscription.add_corrections`\n",
    "1. `.update_conversion_file`\n",
    "This function takes two paramters: `which`: to indicate which file to augment (people, names, places, or upper), and `user_list`: the terms to add.  \n",
    "Only new entries are added.  \n",
    "2. `.add_corrections` \n",
    "This function accepts a list of tuples, e.g.: correction_lst = [('west mckinney', 'Wes McKinney'), ('rashama', 'Reshama')]\n",
    "\n",
    "### TODO: amend `EventTranscription.add_corrections` to only add new entries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='01.1'></a>\n",
    "## Add to Corrections"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Latest additions: 01-27-2021\n",
    "```\n",
    "# corrections:\n",
    "correction_lst = [('andreas miller', 'Andreas Mueller'),\n",
    "                  ('hi ladies', 'PyLadies'),\n",
    "                  ('reishma', 'Reshama'),\n",
    "                  ('pi data', 'PyData'),\n",
    "                  ('sk learn', 'sk-learn'),\n",
    "                  ('dave umbrella', 'Data Umbrella'),\n",
    "                  ('vs code', 'VSCode'),\n",
    "                  ('dusk', 'Dask'),\n",
    "                  ('javascript', 'JavaScript'),\n",
    "                  ('java script', 'JavaScript'),\n",
    "                  ('washington dc', 'Washington DC')\n",
    "                 ]\n",
    "\n",
    "# people\n",
    "['hugo','hashim','emily']\n",
    "\n",
    "# names:\n",
    "['binder','kubernetes','dask','python']\n",
    "\n",
    "# upper:\n",
    "['aws']\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtain the corrections as a dict:\n",
    "\n",
    "corrections = TRX.get_corrections_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Safest way: Run a check  in verbose mode to avoid duplication. You will see the existing pair with identical key but differing value.\n",
    "The `reduced_list` will __not__ include these entries.  \n",
    "_Note: verbose flag implemented to allow use in ipywidgets context._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 ('andreas miller', 'Andreas Mueller') Andreas Mueller\n",
      "1 ('hi ladies', 'PyLadies') PyLadies\n",
      "2 ('reishma', 'Reshama') <not found>\n",
      "3 ('pi data', 'PyData') PyData\n",
      "4 ('sk learn', 'sk-learn') sk-learn\n",
      "5 ('dave umbrella', 'Data Umbrella') Data Umbrella\n",
      "6 ('vs code', 'VSCode') VSCode\n",
      "7 ('dusk', 'Dask') Dask\n",
      "8 ('javascript', 'JavaScript') JavaScript\n",
      "9 ('java script', 'JavaScript') JavaScript\n",
      "10 ('washington dc', 'Washington DC') Washington DC\n",
      "11 ('hiroku', 'HERoku') <different val>: existing: Heroku\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "#### Next, __run__: `: TRX.add_corrections(<reduced list>)`"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Run a check to avoid duplication. \n",
    "# The last line of the output of the verbose version will indicate what to run next:\n",
    "\n",
    "# Verbose version (default):\n",
    "correction_lst = [('andreas miller', 'Andreas Mueller'),\n",
    "                  ('hi ladies', 'PyLadies'),\n",
    "                  ('reishma', 'Reshama'),\n",
    "                  ('pi data', 'PyData'),\n",
    "                  ('sk learn', 'sk-learn'),\n",
    "                  ('dave umbrella', 'Data Umbrella'),\n",
    "                  ('vs code', 'VSCode'),\n",
    "                  ('dusk', 'Dask'),\n",
    "                  ('javascript', 'JavaScript'),\n",
    "                  ('java script', 'JavaScript'),\n",
    "                  ('washington dc', 'Washington DC'),\n",
    "                  ('hiroku', 'HERoku')  # test for difference, which should not be added\n",
    "                 ]\n",
    "check, reduced_list = TRX.check_corrections(corrections, correction_lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "corrections = TRX.add_corrections(reduced_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ALTERNATE WAY: Silent version (param verbose=False):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "correction_lst = [('andreas miller', 'Andreas Mueller'),\n",
    "                  ('hi ladies', 'PyLadies'),\n",
    "                  ('reishma', 'Reshama'),\n",
    "                  ('pi data', 'PyData'),\n",
    "                  ('sk learn', 'sk-learn'),\n",
    "                  ('dave umbrella', 'Data Umbrella'),\n",
    "                  ('vs code', 'VSCode'),\n",
    "                  ('dusk', 'Dask'),\n",
    "                  ('javascript', 'JavaScript'),\n",
    "                  ('java script', 'JavaScript'),\n",
    "                  ('washington dc', 'Washington DC')\n",
    "                 ]\n",
    "check, reduced_list, msg = TRX.check_corrections(corrections, correction_lst, verbose=False)\n",
    "if check:\n",
    "    if 'reduced' in msg:\n",
    "        if reduced_list:\n",
    "            corrections = TRX.add_corrections(reduced_list)\n",
    "    else:\n",
    "        corrections = TRX.add_corrections(correction_lst)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='01.2'></a>\n",
    "## Titlecasing csv files: Names, Places, People\n",
    "---\n",
    "## Add Names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t binder <found>\n",
      "\t kubernetes <found>\n",
      "\t dask <found>\n",
      "\t python <found>\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "#### All found. Nothing to add."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Search the list (verbose mode):\n",
    "\n",
    "new_names = ['binder', 'kubernetes','dask', 'python']\n",
    "\n",
    "names_list = TRX.readcsv(TRX.names_file).names.tolist()\n",
    "\n",
    "check, reduced_list = TRX.check_list(names_list, new_names)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# If update needed:\n",
    "\n",
    "TRX.update_conversion_file(which='names', user_list=<>)\n",
    "\n",
    "# Optional: recall the list to check:\n",
    "names_list = TRX.readcsv(TRX.names_file).names.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Add Places"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t columbia university <found>\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "#### All found. Nothing to add."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "new_places = ['columbia university']\n",
    "places_list = TRX.readcsv(TRX.places_file).places.tolist()\n",
    "\n",
    "check, reduced_list = TRX.check_list(places_list, new_places)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# If update needed:\n",
    "\n",
    "TRX.update_conversion_file(which='places', user_list=<>)\n",
    "#places_list = TRX.readcsv(TRX.places_file).places.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Add People"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t hugo <found>\n",
      "\t hashim <found>\n",
      "\t emily <found>\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "#### All found. Nothing to add."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "people_list = TRX.readcsv(TRX.people_file).people.tolist()\n",
    "new_people = ['hugo','hashim','emily']\n",
    "\n",
    "check, reduced_list = TRX.check_list(people_list, new_people)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# If update needed:\n",
    "\n",
    "TRX.update_conversion_file(which='people', user_list=new_people)\n",
    "#people_list = TRX.readcsv(TRX.people_file).people.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Add Upper terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t nyu <found>\n",
      "\t aws <not found>\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "#### Next, __run__: `TRX.update_substitution_file` with:  `which`=<one of ['names','people','places','upper']>,  `user_list`=\\<reduced list\\>)"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "new_terms = ['nyu', 'aws']\n",
    "upper_list = TRX.readcsv(TRX.upper_file).upper.tolist()\n",
    "\n",
    "check, reduced_list = TRX.check_list(upper_list, new_terms)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# If update needed:\n",
    "\n",
    "TRX.update_conversion_file(which='upper', user_list=reduced_list)\n",
    "#upper_list = TRX.readcsv(TRX.upper_file).upper.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "---\n",
    "<a id='02'></a>\n",
    "# 2. How To Redo the Initial Transcript"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='02.0'></a>\n",
    "## Instantiate the event class for the event you want re-processed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "tr = Meta.TranscriptMeta('20', 2020)  # id, year\n",
    "\n",
    "# This is how you access the event data:\n",
    "tr.event_dict['transcript_md']\n",
    "tr.event_dict['has_transcript']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='02.1'></a>\n",
    "## Case 1:  Redo if any of the Corrections, People, Names, Places, or Upper terms files was updated.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Re-process the captions and reinsert into transcript md file:\n",
    "\n",
    "tr.redo_initial_transcript()\n",
    "tr.insert_md_transcript()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='02.2'></a>\n",
    "## Case 2:  Redo if you want to change the wrap width or the time chuncking\n",
    "To change these formatting parameters, assign new values to `tr.new_minutes_mark` and `tr.new_wrap_width`.  <br>\n",
    "Note:  Default values in YTVAudio class are 4 (minutes) and 120 (characters).  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "tr.new_minutes_mark = 5\n",
    "tr.new_wrap_width = 100\n",
    "  \n",
    "# Re-process the captions and reinsert into transcript md file:\n",
    "tr.redo_initial_transcript()\n",
    "tr.insert_md_transcript()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='02.3'></a>\n",
    "## Visualize: \n",
    "\n",
    "### Visualize the text only:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tr.event_dict['formatted_transcript'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize the Markdown file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mdfile = Meta.REPO_PATH.joinpath(tr.event_dict['year'], tr.event_dict['transcript_md'])\n",
    "Markdown(mdfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "---\n",
    "<a id='03'></a>\n",
    "# 3. How To Download the Audio File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'01-nick-janetakis-command.md'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tr = Meta.TranscriptMeta('01', 2021)  # str(id), year\n",
    "\n",
    "tr.set_YT()\n",
    "tr.YT.download_audio()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "---\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
