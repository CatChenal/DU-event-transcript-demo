{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Run the first cell! (collapsed in JupyterLab)_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path added to sys.path: C:/Users/catch/Documents/GitHub/DU-event-transcript-demo/resources/EventManagement\n",
      "\n",
      "Python ver: 3.7.6 | packaged by conda-forge | (default, Jun  1 2020, 18:11:50) [MSC v.1916 64 bit (AMD64)]\n",
      "Python env: p37\n",
      "OS:         win32\n",
      "Current dir: C:\\Users\\catch\\Documents\\GitHub\\DU-event-transcript-demo\\resources\\EventManagement\\notebooks\n",
      "\n",
      "2021-02-02T12:47:57-05:00\n",
      "\n",
      "CPython 3.7.6\n",
      "IPython 7.16.1\n",
      "\n",
      "compiler   : MSC v.1916 64 bit (AMD64)\n",
      "system     : Windows\n",
      "release    : 10\n",
      "machine    : AMD64\n",
      "processor  : Intel64 Family 6 Model 142 Stepping 10, GenuineIntel\n",
      "CPU cores  : 8\n",
      "interpreter: 64bit\n",
      "numpy  1.19.0\n",
      "pandas 1.0.5\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# To get multiple outputs from one code cell (without using print()):\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = 'all'\n",
    "\n",
    "from IPython import get_ipython\n",
    "from IPython.display import HTML, Markdown, Image\n",
    "\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# For documenting the current environment:\n",
    "def sys_info():\n",
    "    frmt = '\\nPython ver: {}\\nPython env: {}\\n'\n",
    "    frmt += 'OS:         {}\\nCurrent dir: {}\\n'\n",
    "    print(frmt.format(sys.version, \n",
    "                      Path(sys.prefix).name,\n",
    "                      sys.platform,\n",
    "                      Path.cwd()))\n",
    "\n",
    "# For enabling imports from current project code:\n",
    "def add_to_sys_path(this_path, up=False, verbose=True):\n",
    "    \"\"\"\n",
    "    Prepend this_path to sys.path.\n",
    "    If up=True, path refers to parent folder (1 level up).\n",
    "    \"\"\"\n",
    "    newp = Path(this_path).as_posix() # no str method (?)\n",
    "    if up:\n",
    "        newp = Path(this_path).parent.as_posix()\n",
    "\n",
    "    msg = F'Path already in sys.path: {newp}'\n",
    "    if newp not in sys.path:\n",
    "        sys.path.insert(1, newp)\n",
    "        msg = F'Path added to sys.path: {newp}'\n",
    "    if verbose:\n",
    "        print(msg)\n",
    "\n",
    "# If this ipynb file is inside a folder, eg ./notebooks, \n",
    "# the project code is assumed to reside 1 level up:\n",
    "nb_folder = 'notebooks'\n",
    "add_to_sys_path(Path.cwd(), up=Path.cwd().name.startswith(nb_folder))\n",
    "\n",
    "\n",
    "# For py modules/methods discovery:\n",
    "def filter_dir(mdl, filter_str=None, start_with_str='_', exclude=True):\n",
    "    \"\"\"Filter dir(mdl) for method discovery.\n",
    "       Input:\n",
    "       :param mdl (object): module, optionally with submodule path(s), e.g. mdl.submdl1.submdl2.\n",
    "       :param filter_str (str, None): filter all method names containing that string.\n",
    "       :param start_with_str (str, '_'), exclude (bool, True): start_with_str and exclude work \n",
    "              together to perform search on non-dunder methods (default).\n",
    "       Example:\n",
    "       >filter_dir(re) # lists the public methods of the re module.\n",
    "    \"\"\"\n",
    "    search_dir = [d for d in dir(mdl) if not d.startswith(start_with_str) == exclude]\n",
    "    if filter_str is None:\n",
    "        return search_dir\n",
    "    else:\n",
    "        filter_str = filter_str.lower()\n",
    "        return [d for d in search_dir if d.lower().find(filter_str) != -1]\n",
    "\n",
    "# To create often-used subfolders:\n",
    "def get_project_dirs(which=['data', 'images'],\n",
    "                     use_parent=True):\n",
    "    '''Create folder(s) named in `which` at the ipynb parent level.'''\n",
    "    if use_parent:\n",
    "        dir_fn = Path.cwd().parent.joinpath\n",
    "    else:\n",
    "        dir_fn = Path.cwd().joinpath\n",
    "        \n",
    "    dir_lst = []    \n",
    "    for d in which:\n",
    "        DIR = dir_fn(d)\n",
    "        if not DIR.exists():\n",
    "            Path.mkdir(DIR)\n",
    "        dir_lst.append(DIR)\n",
    "    return dir_lst\n",
    "\n",
    "DIR_DATA, DIR_IMG = get_project_dirs()\n",
    "    \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "#pd.set_option(\"display.max_colwidth\", 200)\n",
    "from pprint import pprint as pp\n",
    "\n",
    "\n",
    "# For documenting the current environment:\n",
    "def show_versions():\n",
    "    txt = '<pre><br>'\n",
    "    txt += F'Python:\\t\\t{sys.version}<br>'\n",
    "    txt += F'Python env:\\t{Path(sys.prefix).name}<br>'\n",
    "    txt += F'Numpy:\\t\\t{np.__version__}<br>'\n",
    "    txt += F'Scipy:\\t\\t{sp.__version__}<br>'\n",
    "    txt += F'Pandas:\\t\\t{pd.__version__}<br>'\n",
    "    txt += F'Matplotlib:\\t{mpl.__version__}<br>'\n",
    "    txt += F'Currrent dir: {Path.cwd()}'\n",
    "    txt += '</pre>'\n",
    "    div = f\"\"\"<div class=\"alert alert-info\"><b>Versions:</b><br>{txt}</div>\"\"\"\n",
    "    return HTML(div)\n",
    "\n",
    "\n",
    "# autoreload extension\n",
    "if 'autoreload' not in get_ipython().extension_manager.loaded:\n",
    "    get_ipython().run_line_magic('load_ext', 'autoreload')\n",
    "\n",
    "%autoreload 2\n",
    "\n",
    "#..................\n",
    "sys_info()\n",
    "\n",
    "no_wmark = False\n",
    "try:\n",
    "    %load_ext watermark\n",
    "    %watermark\n",
    "except ModuleNotFoundError:\n",
    "    no_wmark = True\n",
    "\n",
    "if no_wmark:\n",
    "    show_versions()\n",
    "else:\n",
    "    %watermark -iv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from manage import (EventMeta as Meta,\n",
    "                    EventTranscription as TRX,\n",
    "                    Controls as CTR,\n",
    "                    Utils as UTL,\n",
    "                    Audit as AUD)\n",
    "\n",
    "import ipywidgets as ipw\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "---\n",
    "# Audit: coverage of split_url\n",
    "RE: regex in get_id_from_YT_url not working for all md files\n",
    "## Q1: Is `parse_href` working? A1: Yes\n",
    "## Q2: Is video_url working? A2: Yes\n",
    "# Conclusion: Updated (fixed) regex in get_id_from_YT_url."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test meetup...\n",
      "Test youtube...\n",
      "All done.\n"
     ]
    }
   ],
   "source": [
    "UTL.test_split_url()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "---\n",
    "# Audit: which xml files are not lowercase?\n",
    "- Answer by testing 1st paragraph => Modified `xml_caption_to_text` to obtain `Audit.audit_xml_captions`\n",
    "\n",
    "## Audit conclusion:\n",
    "The xml files have consistently been lowercase since event 12, hence this does not warrant implementing\n",
    "of a by-pass to text cleaning if they are not (the corrections would still need applying but they would not\n",
    "be optimal without adding special cases if text is not lowercase)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Captions case check (on 1st P with minutes_mark= 1):\n",
      "03, 2020:: Lower= False\n",
      "everyone I am doing a recording of the scraping presentation and the original recording from the webinar didn't come out well so this is just a recording in today's presentation I'm going to talk about web scraping we're going to look at the website Poshmark comm and we're going to use Python and some additional packages to gather the data so agenda I'm gonna give a quick introduction about myself and the group then we're going to talk about web scraping and high level then we'll walk through a code example I'm going to share the code files so you can walk through it on your own as well and then during the webinar there was obviously QA it's a little bit about me I'm a product manager with General Assembly I used to run operations at an online data science bootcamp and that's kind of where I picked up everything I know about Python and programming and data science and \n",
      ")\n",
      "04, 2020:: Lower= False\n",
      "all right it's 7:05 so I'll do my intra bit and we can happen to yours hey everyone my name is ty I will be doing an intro quick and true and then Ali will be giving her presentation if you have questions there's a QA function and zoom so you can ask the quench questions there if I can answer it I'll help answer if not we will run through them at the end okay so I'm just gonna give a quick introduction then I will talk and then we'll do QA this will be recorded so if something happens you have to leave or someone you know wasn't able to attend the recording will automatically be sent out by General Assembly usually I think it's within a day but it might be two days so just an intro on how a she teaches people how to code she loves Python JavaScript and talking about code and she's always been interested in programming art and education she's on the distinguished \n",
      ")\n",
      "05, 2020:: Lower= False\n",
      "hey everybody so this is an instruction video on how to contribute to source projects in particular to cycle learn I'm andreas Miller one of the core developers of recycle or project thanks for Reshma and the data umbrella for organizing this sprint so I really want to give you just a very brief overview of the technology behind contributing to open source and the steps of getting your first cohesions in so first off a great way to communicate with the developers is the getter channel you can find that at get heard I am slashed so I could learn for a spread there is this channel called sprint and there's also a cycle to learn channel that's just a general channel that you can find that Gator that I am slash scikit-learn slash I could learn \n",
      ")\n",
      "06, 2020:: Lower= False\n",
      "hello my name is Rashmi and I'm going to go through an example of submitting a pull request or a PR I participated in my first scikit-learn sprint about a year and a half ago and I'm happy to share an example once you learn this example is gonna be for the SK learn repo but once you've learned how to do it for this repository you can do it for any repository on github so the first thing that I'm going to do is I'm just gonna make sure that I have my I have some things set up and the first thing is I'm working out of my home directory guys I just want to make sure and see which which Python I am using with the system is of anaconda I am using the anaconda version which is good I also want to just confirm what version of Python I'm using and it's version 3 6 8 and I just want to check one more thing which is do I have get installed and I do that's great so the next thing that \n",
      ")\n",
      "07, 2020:: Lower= False\n",
      "okay so it's it's really great my name is Rashmi Shaikh and I am the founder of data umbrella I am also an organizer for NYC hi ladies and I am based out of New York City welcome to our welcome to our session the mission of data umbrella is to provide a welcoming and educational space for underrepresented persons in data science we welcome allies to help us in our mission and we welcome all different skill levels we are on twitter at theta umbrella so feel free to tweet and share about the event and follow us also there's a LinkedIn page for us where I usually share job posting so you're welcome to join there and there's information on the website about a discord for community I just want to go over the code of conduct that you know we're dedicated to providing harassment free experience for everyone be kind to others be professional and respectful we really want to build a friendly \n",
      ")\n",
      "08, 2020:: Lower= False\n",
      "Oh you you you you if you have a you can use the QA function so if you're on zoom and you hover over the video it should be on the bottom below the video it looks like QA and you can ask questions there and then we'll spend some time to answer them we do a break in the middle of the talk and then at the end of the talk as well you \n",
      ")\n",
      "09, 2020:: Lower= False\n",
      "there you go okay everybody welcome to data umbrella and PI ladies online event just sort of let you know how well did it how the event is gonna go I'm gonna do an introduction about the meetup group Sam Bell is going to give a talk and we'll have Q&A will also sort of watch the Q&A every 10 minutes or so and answer questions along the way just to let you know this event is being recorded about me I'm a statistician data scientist I founded data umbrella and I'm also a hi ladies organizer a New York City chapter and I am on twitter at reached is the mission of data umbrella is to provide a welcoming and educational space for underrepresented persons in the fields of data science our website has information we're on twitter if you'd like to share about this event and just know that we are a \n",
      ")\n",
      "10, 2020:: Lower= True\n",
      "hi everyone welcome to data umbrella webinar um also co-promoted with nyc pi ladies i'm going to do a brief introduction and then turn it over to emily for her presentation um and then after that what you could do is you can place any questions in the q a and um at the end uh emily will answer questions from them but just and just a reminder to reiterate this talk is being recorded about me um i'm a statistician and data scientist um i'm the founder of data brella and i'm also an nyc pie ladies organizer the mission of data umbrella is to provide a welcoming and educational space for underrepresented persons in the field of data science and machine learning we welcome allies who support our cause our home page is dataumbrella.org check it out we're also on twitter and we are a volunteer run organization \n",
      ")\n",
      "11, 2020:: Lower= False\n",
      "everybody welcome to data umbrellas webinar I'm just gonna go over a brief introduction so I'm gonna introduce the umbrella of Rebecca Kelly's going to do her talk and then you can ask questions in the Q&A tab or you can ask in the chat and I'll just move the questions over to the Q&A tab and depending on how the questions come in we can sort of I made into a home turf Rebecca if it's a good time to interrupt her but we'll get the questions answered and this webinar is being recorded about me I am the founder of data umbrella I'm a statistician by training and a data scientist and I also organize for the New York City chapter of Pi ladies and I'm on Twitter evasion is the mission of data umbrella is to provide a welcoming education inclusive space for underrepresented persons in data science and we are a volunteer run organization \n",
      ")\n",
      "12, 2020:: Lower= True\n",
      "hey everybody welcome to a data umbrella webinar um i am joining um from new york and uh i'm just gonna do a a brief introduction about data umbrella and then we'll get started on the um webinar um so it'll be it'll sort of go like i'll do the introduction um we'll do the talk and then you can post any questions in the chat or in the q a and we'll sort of answer those as they pile up over time and just to let people know this will be recorded and will be available on our youtube i posted a link to youtube in the chat if you're not able to see it just let me know and i can share it again about me i'm the founder of data umbrella i'm a statistician data scientist and i am also an organizer for the new york city chapter of \n",
      ")\n",
      "13, 2020:: Lower= True\n",
      "hey everybody welcome to data umbrella's webinar um thanks for joining us um i'm going to go over um a brief introduction about data umbrella and then liz is going to do her talk and then um for the q a for the questions you can feel free to post them in chat or in the q a tab and i'll sort of moderate the session and ask the questions as i can you know find a good place to interrupt liz as she's presenting now this webinar will be is being recorded actually okay a little bit about me i am a statistician and data scientist um i am based in new york city i am the founder of data umbrella and i'm also an organizer for the new york city chapter of pi ladies you can find me on twitter with at reishmaest and i'm also on github and linkedin with um with the same username data umbrella our mission is to provide a welcoming and educational space for \n",
      ")\n",
      "14, 2020:: Lower= True\n",
      "hi everyone welcome to data umbrella's webinar uh my name is reshma and i'm just going to go over some some housekeeping um the way that the webinar will work tonight is that i do a brief introduction megan is going to be doing um her talk and then we'll um what you can do is there's a tab on the webinar platform for q a so feel free to post any questions there and when you know when it's a good breaking point megan will answer any questions that you have this webinar is being recorded about me uh i am a statistician slash data scientist i am the founder of data umbrella and i'm also an organizer for the new york city chapter of pi ladies and you can find me on twitter at reshma s i'm also on linkedin and github with the same username \n",
      ")\n",
      "15, 2020:: Lower= True\n",
      "hi everybody welcome to data umbrella um i'm going to just go over the agenda of how the webinar is going to go i'm going to do a brief introduction emmanuelle um will do her presentation on plotly and you can ask questions on the q a tab and so we'll sort of check questions when it's a good time to stop um but not to worry your questions will get answered some of them might be at the end but we will answer all questions and this webinar is being recorded a little bit about myself i'm a statistician data scientist i'm the founder of data umbrella and i'm also an organizer for the new york city chapter of pi ladies you can find me on twitter github and linkedin as reishmas data umbrella is our mission is to provide inclusive and welcoming space for underrepresented persons in data science \n",
      ")\n",
      "16, 2020:: Lower= True\n",
      "okay hello and welcome to data umbrella's webinar for um october so i'm just going to go over the agenda i'm going to do a brief introduction then there will be the workshop by hugo and james and you can ask questions along the way in the chat or actually the best place to ask questions is the q a and there's an option to upvote as well um so yet um asking the q a if you happen to post it on the chat by mistake i can also transfer it over to q a so that would be fine too and this webinar is being recorded uh briefly about me i am a statistician and data scientist and i am the founder of data umbrella um i am on a lot of platforms as rachmas so feel free to follow me on twitter and linkedin we have a code of conduct we're dedicated to providing harassment free experience for everyone \n",
      ")\n",
      "17, 2020:: Lower= True\n",
      "hello everyone thank you for joining our webinar for today uh thanks for joining data umbrella i'm gonna do a quick introduction uh carol willing is going to do her talk and we'll have a q a session at the end and and this webinar is being recorded a little bit about me i'm a statistician data scientist i'm the founder of data umbrella and i am on twitter linkedin github has raised my s feel free to follow me we have a code of conduct we're dedicated to providing harassment free professional respectful experience for everyone this applies to the chat as well um thank you for helping make this a welcoming and friendly community for all of us about data umbrella we're an inclusive community for underrepresented persons in data science we welcome allies to join us and we are a volunteer run organization so how can you support data umbrella the \n",
      ")\n",
      "18, 2020:: Lower= True\n",
      "hello everyone and welcome to data umbrella's webinar i'm going to do a brief presentation um i'm going to do a quick introduction um the talk is going to be there and we are going to have a q a at the end this talk is being recorded if you have any questions there's a q a tab on this platform so if you could post questions there that's a good place to aggregate them if you happen to place them in the chat i can also easily you know transfer them over to q a but it is easier if you post them in the q a tab this webinar is being recorded a little bit about me briefly i'm a statistician data scientist i'm a founder i am the founder of data umbrella and i am on twitter linkedin and github as reishima so feel free to follow me um if you would like we have a code of conduct uh we're quite strict with our code of conduct because one of the reasons that this community was created is to provide a safe and inclusive environment for people from underrepresented groups \n",
      ")\n",
      "19, 2020:: Lower= True\n",
      "hello everybody welcome to data umbrella's webinar so um our our processes usually i do a quick introduction um maddie will do his talk and you know her q a um if you have questions you can on chat or you can post them in the q a tab i can easily move questions from the chat over to the q a so that's fine um and this webinar is being recorded and will be available on youtube um usually within a couple of days but sometimes a week depending on how much editing has to be done a quick introduction about myself i i'm the founder of data umbrella i'm a statistician data scientist by training and i am available on twitter linkedin and github at rachmas so feel free to follow me if you'd like we have a code of conduct here uh we're dedicated to providing harassment free experience for everyone this applies to \n",
      ")\n",
      "20, 2020:: Lower= True\n",
      "hello everyone and welcome to data umbrella's webinar our our agenda is going to be i'm going to do a quick introduction and then marco will be doing his talk and we have q a at the end this is actually a special webinar because what we will do after marco's presentation is we're going to go over to discord and if anybody wants to set up their environment we have somebody to help people who are viewing this reporting after today is tuesday december 15th a little bit about data umbrella we are an inclusive community for underrepresented persons in data science and we are a volunteer run organization a little bit about me i'm a statistician data scientist i have a master's in statistics and um let me just get my slides back i'm going to uh okay \n",
      ")\n",
      "01, 2021:: Lower= True\n",
      "hello everyone and welcome to our data umbrella webinar this is our first webinar of 2021. i'm going to do a quick introduction and then nick will do his talk and we'll open it up for q a you can also ask questions in the question tab throughout the presentation and we'll sort of break whenever it's a good time to break and this webinar is being recorded data umbrella is an inclusive community for underrepresented persons in data science and we are volunteer run a brief couple of things about me i'm a statistician data scientist and i have an ms in masters in statistics and an mba from nyu and i am the founder of data umbrella um if you are interested in learning more about what i'm doing you can follow me on twitter linkedin or github i have the same handle raishma s we have a code of conduct here and we're \n",
      ")\n",
      "02, 2021:: Lower= True\n",
      "okay hello and welcome to data umbrella's webinar for um october so i'm just going to go over the agenda i'm going to do a brief introduction then there will be the workshop by hugo and james and you can ask questions along the way in the chat or actually the best place to ask questions is the q a and there's an option to upvote as well um so yet um asking the q a if you happen to post it on the chat by mistake i can also transfer it over to q a so that would be fine too and this webinar is being recorded uh briefly about me i am a statistician and data scientist and i am the founder of data umbrella um i am on a lot of platforms as rachmas so feel free to follow me on twitter and linkedin we have a code of conduct we're dedicated to providing harassment free experience for everyone \n",
      ")\n",
      "03, 2021:: Lower= True\n",
      "okay hello and welcome to data umbrella's webinar for um october so i'm just going to go over the agenda i'm going to do a brief introduction then there will be the workshop by hugo and james and you can ask questions along the way in the chat or actually the best place to ask questions is the q a and there's an option to upvote as well um so yet um asking the q a if you happen to post it on the chat by mistake i can also transfer it over to q a so that would be fine too and this webinar is being recorded uh briefly about me i am a statistician and data scientist and i am the founder of data umbrella um i am on a lot of platforms as rachmas so feel free to follow me on twitter and linkedin we have a code of conduct we're dedicated to providing harassment free experience for everyone \n",
      ")\n",
      "get_all_transcripts [meta_only=False, audit_captions=True, replace_xml=False, replace_trx=False]:: done!\n"
     ]
    }
   ],
   "source": [
    "AUD.get_all_transcripts(audit_captions=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "---\n",
    "## DONE: Test: Change GrispecLayout (\"a regulary-spaced grid\": missed that!) to GridBox"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "---\n",
    "# Current task: Incorporate modification to propercasing files in Edit page."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "df185226c4914dff81e49b73fa31498e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "AppLayout(children=(Accordion(children=(VBox(children=(ToggleButtons(button_style='info', options=('Enter Info…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "AC = CTR.AppControls()  # class, GUI controls instantiation\n",
    "app = AC.app            # AppLayout method\n",
    "app"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2f7d2ed5f21341f19e12a1722f54b971",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "GridBox(children=(HTML(value='<H3>Select the Event Year, Id, AV player (and if need be, update the Transcriber…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "grid = AC.PC.page.children[0]  #grid header\n",
    "type(grid)\n",
    "grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "\n",
    "# global (self.) wgts:\n",
    "sel_yr = ipw.Select(options=[2020, 2021, 2022, 2023, 2024, 2025,2026,\n",
    "                             2027, 2028,2029],\n",
    "                    value=None,\n",
    "                    layout=ipw.Layout(width='55px'))\n",
    "sel_idn = ipw.Select(options=['03','02','03'],\n",
    "                     value=None,\n",
    "                     layout=ipw.Layout(width='55px'))\n",
    "sel_status = ipw.Select(options=CTR.status_opts,\n",
    "                        value=None,\n",
    "                        disabled=True)\n",
    "sel_files = ipw.widgets.Select(options=['People','Names','Places',\n",
    "                                        'Upper','Corrections'],\n",
    "                               value=None,\n",
    "                               disabled=False)\n",
    "\n",
    "av_radio = ipw.RadioButtons(options=['Audio','Video'], value='Audio')\n",
    "transcriber_txt = ipw.Text(value='? (transcriber)')\n",
    "txt_input = ipw.Text(layout=ipw.Layout(width='420px'))\n",
    "\n",
    "lo_out = ipw.Layout(height='30px')\n",
    "sel_files_out = ipw.Output()\n",
    "sel_idn_out = ipw.Output(layout=lo_out)\n",
    "btn_load_out = ipw.Output()\n",
    "btn_update_out = ipw.Output()\n",
    "btn_redo_out = ipw.Output()\n",
    "\n",
    "btn_load = ipw.Button(description='LOAD',\n",
    "                      button_style='info',\n",
    "                      disabled=True)\n",
    "btn_update = ipw.Button(description='UPDATE',\n",
    "                        tooltip='Validate & save your changes.',\n",
    "                        button_style='info',\n",
    "                        disabled=False)\n",
    "btn_redo = ipw.Button(description='REPROCESS',\n",
    "                      tooltip='Redo the transcription with the new files.',\n",
    "                      button_style='info',\n",
    "                      disabled=True)\n",
    "# ........................................................... \n",
    "\n",
    "def click_btn_redo(b):\n",
    "    btn_redo_out.clear_output()\n",
    "    with btn_redo_out:\n",
    "        print(\"Clicked!\")\n",
    "        \n",
    "def click_btn_update(b):\n",
    "    #............................. HBox . Accordion . GridBox\n",
    "    footer_g = page_hdr_grid.children[3].children[0].children[0]\n",
    "    v_file = footer_g.children[0].children[0].value\n",
    "    v_entries = footer_g.children[0].children[1].children[1].value or None\n",
    "    if v_file is None or v_entries is None:\n",
    "        btn_update_out.clear_output()\n",
    "        with btn_update_out:\n",
    "            print('Select a file and provide new entries.')\n",
    "    else:\n",
    "        # Enable the other sidebar btn\n",
    "        #footer_grid.children[1].children[1].children[0].disabled = False\n",
    "        with btn_update_out:\n",
    "            print('Doing fake update...')\n",
    "        update_ok = True\n",
    "        if update_ok:\n",
    "            btn_redo.disabled = False\n",
    "        else:\n",
    "            with btn_update_out:\n",
    "                print('Coud not fake update!')\n",
    "\n",
    "        \n",
    "def obs_sel_files(change):\n",
    "    \"\"\"Observe fn for sel_files.\"\"\"\n",
    "    fname = change['owner'].value\n",
    "    if fname is None:\n",
    "        msg = \"<h5>Use this text box to enter your list of entries:</h5>\"\n",
    "    elif fname == 'Corrections':\n",
    "        msg = \"<h5>Provide your entries as a list of string tuples, \"\n",
    "        msg += \"e.g.: <pre>('&lt;from&gt;', '&lt;to&gt;'), ...</pre></h5>\"\n",
    "    else:\n",
    "        msg = \"<h5>Separate your entries with a comma.</h5>\"\n",
    "    sel_files_out.clear_output()\n",
    "    with sel_files_out:\n",
    "        display(HTML(msg))\n",
    "\n",
    "sel_files.observe(obs_sel_files)\n",
    "btn_update.on_click(click_btn_update)\n",
    "btn_redo.on_click(click_btn_redo)\n",
    "\n",
    "\n",
    "def get_update_grid():        \n",
    "    g = get_grid(2, 'Update the propercasing or corrections files',\n",
    "                 exclude=['header', 'footer'])\n",
    "    with sel_files_out:\n",
    "        msg = \"<h5>Use this text box to enter your entries:</h5>\"\n",
    "        display(HTML(msg))\n",
    "\n",
    "    vbx = partial(ipw.VBox,\n",
    "                  layout=ipw.Layout(display='flex',\n",
    "                                    flex_flow='column',\n",
    "                                    align_items='flex-start'))\n",
    "    \n",
    "    g.children[0].children = [sel_files,\n",
    "                              vbx([sel_files_out, txt_input])]\n",
    "    g.children[1].children = [vbx([btn_update, btn_update_out]),\n",
    "                              vbx([btn_redo, btn_redo_out])]\n",
    "    return g\n",
    "\n",
    "\n",
    "def populate_grid(idx, g):\n",
    "    \"\"\"\n",
    "    Populate GridBox g main, sidebar and footer (if idx==2) areas.\n",
    "    :param: idx: Page index.\n",
    "    :param: g: GridBox of a page header.\n",
    "    \"\"\"\n",
    "    if  idx == 0:\n",
    "        return\n",
    "    \n",
    "    if idx == 1:\n",
    "        g.children[1].children = [sel_yr, sel_idn, sel_idn_out]\n",
    "        g.children[2].children = [btn_load, btn_load_out]\n",
    "    else:\n",
    "        g.children[1].children = [sel_yr, sel_idn,\n",
    "                                 ipw.VBox([sel_idn_out,\n",
    "                                           av_radio]),\n",
    "                                 ipw.VBox([transcriber_txt,\n",
    "                                           sel_status])]\n",
    "        g.children[2].children = [btn_load, btn_load_out]\n",
    "        # load controls for updating text processing files in Accordion:\n",
    "        g.children[3].children = [CTR.wgt_Accord([get_update_grid()])]\n",
    "\n",
    "\n",
    "def get_grid(idx, grid_name=None, header_fn=None, exclude=None):\n",
    "    \"\"\"\n",
    "    Wrapper to get starter GridBox with pre-defined areas to\n",
    "    obtain, at most, a 3x3 grid.\n",
    "    :param: idx: index referencing a caller widget, i.e. tab index.\n",
    "    :param: grid_name: Name (attribute) to id the grid\n",
    "    :param: exclude: None (default), or header|footer areas to exclude, e.g ['footer']\n",
    "    :param: header_fn: Function populating the page header grid area if any;\n",
    "                       Takes idx as param: header_fn(idx).\n",
    "    \"\"\"\n",
    "    if idx not in [1,2]:\n",
    "        return\n",
    "    \n",
    "    def lo_grid_area(a):\n",
    "        return ipw.Layout(width='auto', grid_area=a)\n",
    "        \n",
    "    # always included:\n",
    "    main = ipw.HBox(children=[],\n",
    "                    layout=lo_grid_area('main'))\n",
    "    sidebar = ipw.VBox(children=[],\n",
    "                       layout=lo_grid_area('sidebar'))\n",
    "               \n",
    "    if exclude is not None:\n",
    "        if len(exclude) == 2:\n",
    "            # Assume header & footer excluded\n",
    "            tpl_areas= '''\"main main sidebar\"'''\n",
    "            kids = [main, sidebar]\n",
    "        else:    \n",
    "            if 'header' not in exclude:\n",
    "                tpl_areas= '''\n",
    "                    \"header header header\"\n",
    "                    \"main main sidebar\"\n",
    "                    '''\n",
    "                if header_fn is None:\n",
    "                    header = ipw.HBox(children=[],\n",
    "                                      layout=lo_grid_area('header'))\n",
    "                else:\n",
    "                    header = header_fn(idx)\n",
    "\n",
    "                kids = [header, main, sidebar]\n",
    "\n",
    "            if 'footer' not in exclude:\n",
    "                tpl_areas= '''\n",
    "                    \"main main sidebar\"\n",
    "                    \"footer footer footer\"\n",
    "                    '''\n",
    "                footer = ipw.HBox(children=[],\n",
    "                                  layout=lo_grid_area('footer'))\n",
    "                kids = [main, sidebar, footer]\n",
    "    else:\n",
    "        tpl_areas= '''\n",
    "            \"header header header\"\n",
    "            \"main main sidebar\"\n",
    "            \"footer footer footer\"\n",
    "            '''\n",
    "        if header_fn is None:\n",
    "            header = ipw.HBox(children=[],\n",
    "                              layout=lo_grid_area('header'))\n",
    "        else:\n",
    "            header = header_fn(idx)\n",
    "        footer = ipw.HBox(children=[],\n",
    "                          layout=lo_grid_area('footer'))            \n",
    "\n",
    "        kids = [header, main, sidebar, footer]\n",
    "\n",
    "    lo_grid = ipw.Layout(grid_template_rows='auto auto auto',\n",
    "                         grid_template_columns='1fr, 1fr, 1fr', \n",
    "                         grid_template_areas= tpl_areas)\n",
    "    grid = ipw.GridBox(children=kids,\n",
    "                       layout=lo_grid)\n",
    "\n",
    "    setattr(grid, 'name', grid_name or '')\n",
    "\n",
    "    return grid\n",
    "\n",
    "page_hdr_grid = get_grid(2, header_fn=CTR.get_info_banner)\n",
    "populate_grid(2, page_hdr_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "099436731fc741b7821228a69e1af541",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "GridBox(children=(HTML(value='<H3>Select the Event Year, Id, AV player (and if need be, update the Transcriber…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "page_hdr_grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Corrections', \"('dummy', 'Entry'), ('foo', 'bar'),\")"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "footer_g = page_hdr_grid.children[3].children[0].children[0]\n",
    "\n",
    "v_file = footer_g.children[0].children[0].value\n",
    "v_entries = footer_g.children[0].children[1].children[1].value or None\n",
    "v_file, v_entries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WindowsPath('C:/Users/catch/Documents/GitHub/DU-event-transcript-demo/resources/EventManagement/data/upper_terms.csv')"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fname = TRX.substitutions['upper']\n",
    "fname"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid, msg = validate_user_list(v_entries, v_file, verbose=False)\n",
    "if valid is None:\n",
    "    with btn_update_out:\n",
    "        print(msg)\n",
    "else:\n",
    "    if v_file == 'Corrections':\n",
    "        corrections = TRX.get_corrections_dict()\n",
    "        tot, reduced_list, msg = TRX.check_corrections(corrections, valid,\n",
    "                                                       verbose=False)\n",
    "        if tot:\n",
    "            if 'reduced' in msg:\n",
    "                if reduced_list:\n",
    "                    TRX.add_corrections(reduced_list, return_dict=False)\n",
    "            else:\n",
    "                TRX.add_corrections(valid, return_dict=False)\n",
    "        else:\n",
    "            with btn_update_out:\n",
    "                print(msg)\n",
    "            \n",
    "    else:\n",
    "        v_file = v_file.lower()\n",
    "        fname = TRX.substitutions[v_file]\n",
    "        current_list = TRX.readcsv(fname)[v_file].tolist()\n",
    "\n",
    "        tot, reduced_list = TRX.check_list(current_list, valid, verbose=False)\n",
    "        if tot:\n",
    "            if 'reduced' in msg:\n",
    "                if reduced_list:\n",
    "                    TRX.update_conversion_file(v_file, reduced_list)\n",
    "            else:\n",
    "                TRX.update_conversion_file(which=v_file, valid)\n",
    "        else:\n",
    "            with btn_update_out:\n",
    "                print(msg)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_user_list(entries, file, verbose=False):\n",
    "    \"\"\"\n",
    "    Return a list of validated entries (None or list) along \n",
    "    with a message if verbose=False.\n",
    "    \"\"\"\n",
    "    entries = entries.strip()\n",
    "    if entries[-1] == ',':\n",
    "        entries = entries[:-1]\n",
    "        \n",
    "    if file == 'Corrections':\n",
    "        validated = []\n",
    "        \n",
    "        cnt = Counter(entries)\n",
    "        if cnt['('] != cnt[')']:\n",
    "            if cnt['('] > cnt[')']:\n",
    "                msg = \"Missing a closing parenthesis!\"\n",
    "            else:\n",
    "                msg = \"Missing an opening parenthesis!\"\n",
    "            if verbose:\n",
    "                print(msg)\n",
    "                return None\n",
    "            else:\n",
    "                return None, msg\n",
    "        \n",
    "        p = entries.partition(')')\n",
    "        while p[0]:\n",
    "            p0 = p[0][1:].split(',')\n",
    "            try:\n",
    "                str_from = eval(p0[0].strip().lower())\n",
    "                str_to = eval(p0[1].strip())\n",
    "            except:\n",
    "                msg = \"Could not parse tuples!\"\n",
    "                if verbose:\n",
    "                    print(msg)\n",
    "                    return None\n",
    "                else:\n",
    "                    return None, msg\n",
    "                \n",
    "            validated.append((str_from, str_to))\n",
    "            if p[2] != '':\n",
    "                p2 = p[2][1:].strip()\n",
    "                p = p2.partition(')')\n",
    "            else:\n",
    "                break\n",
    "    else:\n",
    "        try:\n",
    "            validated = [eval(e.strip().lower()) for e in entries.split(',')]\n",
    "        except:\n",
    "            msg = \"Could not parse list!\"\n",
    "            if verbose:\n",
    "                print(msg)\n",
    "                return None\n",
    "            else:\n",
    "                return None, msg\n",
    "            \n",
    "    return validated, 'OK'\n",
    "        \n",
    "\n",
    "def test_validate_user_list():\n",
    "    corr_val1 = \"('dummy', 'Entry')\"\n",
    "    corr_val2 = \"('dummy', 'Entry'), ('foo', 'list'), \"\n",
    "    lst_val1 = \"'dummy', 'Entry'\"\n",
    "    lst_val2 = \"'dummy', 'Entry', 'foo', 'bar', \"\n",
    "    lst_val3 = \"'cat chenal', 'will tell', \"\n",
    "\n",
    "    validate_user_list(corr_val1, 'Corrections')\n",
    "    validate_user_list(corr_val2, 'Corrections')\n",
    "    validate_user_list(lst_val1, 'Names')\n",
    "    validate_user_list(lst_val2, 'Places')\n",
    "    validate_user_list(lst_val3, 'People')\n",
    "    \n",
    "    #new tests:\n",
    "    validate_user_list(lst_val1, 'Corrections')\n",
    "    validate_user_list(corr_val1, 'Upper')\n",
    "    \n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "corr_val2 = \"('dummy', 'Entry'), ('foo', 'list'), \".lower()\n",
    "corr_val2\n",
    "corr_val2 = re.sub(\"[()\\[\\]]\", '', corr_val2)\n",
    "corr_val2\n",
    "```\n",
    "\"('dummy', 'entry'), ('foo', 'list'), \"\n",
    "\"'dummy', 'entry', 'foo', 'list', \"\n",
    "```"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "def get_sel_hdr_grid(idx, header_fn=None):\n",
    "    if idx not in [1,2]:\n",
    "        return\n",
    "    \n",
    "    if header_fn is None:\n",
    "        header = ipw.HBox(children=[],\n",
    "                    layout=ipw.Layout(width='auto',\n",
    "                                      grid_area='header'))\n",
    "    else:\n",
    "        header = header_fn(idx)\n",
    "        \n",
    "    main = ipw.HBox(children=[],\n",
    "                    layout=ipw.Layout(width='auto',\n",
    "                                      grid_area='main'))\n",
    "    sidebar = ipw.VBox(children=[],\n",
    "                       layout=ipw.Layout(width='auto',\n",
    "                                         grid_area='sidebar'))\n",
    "    footer  = ipw.HBox([],\n",
    "                       layout=ipw.Layout(width='auto',\n",
    "                                         grid_area='footer'))\n",
    "    \n",
    "    lo_grid = ipw.Layout(grid_template_rows='auto auto auto',\n",
    "                         grid_template_columns='1fr, 1fr, 1fr', \n",
    "                         grid_template_areas= '''\"header header header\"\n",
    "                            \"main main sidebar\"\n",
    "                            \"footer footer footer\"\n",
    "                            ''')\n",
    "    grid = ipw.GridBox(children=[header, main, sidebar, footer],\n",
    "                       layout=lo_grid) \n",
    "\n",
    "    return grid\n",
    "    \n",
    "def populate_sel_hdr_grid(idx, g):\n",
    "    \"\"\"Populate g::.sel_hdr_grid.\"\"\"\n",
    "\n",
    "    if  idx == 0:\n",
    "        return\n",
    "    if idx == 1:\n",
    "        g.children[1].children = [sel_yr, sel_idn, sel_idn_out]\n",
    "        g.children[2].children = [btn_load, btn_load_out]\n",
    "    else:\n",
    "        g.children[1].children = [sel_yr, sel_idn,\n",
    "                                 ipw.VBox([sel_idn_out,\n",
    "                                           av_radio]),\n",
    "                                 ipw.VBox([transcriber_txt,\n",
    "                                           sel_status])]\n",
    "        g.children[2].children = [btn_load, btn_load_out,\n",
    "                                 ipw.VBox(children=[btn_conversions,\n",
    "                                                    btn_conversions_out])\n",
    "                                 ]    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "ix = app.center.selected_index\n",
    "\n",
    "#AC.PC.page.children[0]  #grid header\n",
    "# code to access btn: \n",
    "AC.PC.page.children[0][1,-1].children[0]\n",
    "#AC.PC.btn_load.disabled"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#input_form = \n",
    "#self.PC.page.children[1].children[0]\n",
    "initial_file = AC.PC.page.children[0][1,1].children[-1].outputs[0]['text'][5:-1]\n",
    "#user_dict after update:\n",
    "d = CTR.get_accordion_entries(AC.PC.page.children[1].children[0])\n",
    "d['idn'] = AC.PC.TR.idn\n",
    "d = AC.PC.TR.set_path_keys(d)\n",
    "d['transcript_md']\n",
    "if initial_file != d['transcript_md']:\n",
    "    print(F'Delete file: {initial_file}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "---\n",
    "# Test: Horizontal RadioButtons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c39b3d57ecf54e8e8704fa260c52e3f9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "RadioButtons(layout=Layout(flex_flow='row'), options=('Audio', 'Video'), value='Audio')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "lo_radio = ipw.Layout(flex_flow='row')\n",
    "av_radio2 = ipw.RadioButtons(options=['Audio','Video'], value='Audio',\n",
    "                            layout=lo_radio)\n",
    "av_radio2"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "source": [
    "ctr_kids = len(app.center.children) # n tabs\n",
    "for k in range(ctr_kids):\n",
    "    type(app.center.children[k])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "---\n",
    "# Debug new update_readme(): FIXED\n",
    "- doubles up the table\n",
    "- add a row even for an event update"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# NEW event:\n",
    "# 0. instanciate class:\n",
    "tm = Meta.TranscriptMeta() \n",
    "tm.NEW\n",
    "#tm.event_dict\n",
    "\n",
    "# 1. update a dict copy, starting from dummy data\n",
    "#    or: make copy of tm.event_dict for updating\n",
    "#        d = tm.event_dict.copy\n",
    "#        + do updates on d\n",
    "d = Meta.get_dummy_data()\n",
    "d['presenter'] =  'cat chenal, sing song'\n",
    "d['notes'] = 'Test, 04 dummy transcript'\n",
    "d['title_kw'] = 'demo demo'\n",
    "# reset (bc would be wrong w/dummy data)\n",
    "d['year'] = tm.event_dict['year']\n",
    "d['idn'] = tm.event_dict['idn']\n",
    "\n",
    "# 2. assign the new dict to tm.event_dict:\n",
    "tm.update_dict(d)\n",
    "\n",
    "# 3. update readme file:\n",
    "tm.update_readme()\n",
    "\n",
    "# 4. save the transcript md file:\n",
    "tm.save_transcript_md()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "---\n",
    "# Fix problem with event numbering from df :: new event dict in Meta :: FIXED\n",
    "```\n",
    "    def new_event_dict(self):\n",
    "        \"\"\"\n",
    "        Create a 'starter' event dict with event id generated\n",
    "        from the readme table df.\n",
    "        \"\"\"\n",
    "        new_dict = self.get_event_dict()\n",
    "\n",
    "        # Update dict with defaults:\n",
    "        new_dict['year'] = self.year\n",
    "        new = self.df.index.argmax() + self.row_offset\n",
    "        self.idn = idn_frmt(new)\n",
    "        new_dict['idn'] = self.idn\n",
    "        new_dict['transcriber'] = '?'\n",
    "        new_dict['extra_references'] = ''\n",
    "        new_dict['has_transcript'] = False\n",
    "        new_dict['status'] = TrStatus.TODO.value\n",
    "        new_dict['notes'] = ''\n",
    "        new_dict['video_href_w'] = DEF_IMG_W #thumbnail\n",
    "        \n",
    "        v1 = self.insertion_idx(HDR_TPL.format(**new_dict))\n",
    "        new_dict['trans_idx'] = v1\n",
    "        return new_dict\n",
    "``` "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TO DO:\n",
    "\n",
    "1. Produce the program flow chart depending on user status, e.g"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "---\n",
    "# Utils for documenting the project\n",
    "---"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "import networkx as nx\n",
    "from networkx.drawing.nx_pydot import pydot_layout\n",
    "filter_dir(nx.drawing.nx_pydot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test: https://nbviewer.jupyter.org/github/xflr6/graphviz/blob/master/examples/notebook.ipynb\n",
    "\n",
    "import os\n",
    "from graphviz import Digraph, Source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_dir(Digraph)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "Digraph?\n",
    "Init signature:\n",
    "Digraph(\n",
    "    name=None,\n",
    "    comment=None,\n",
    "    filename=None,\n",
    "    directory=None,\n",
    "    format=None,\n",
    "    engine=None,\n",
    "    encoding='utf-8',\n",
    "    graph_attr=None,\n",
    "    node_attr=None,\n",
    "    edge_attr=None,\n",
    "    body=None,\n",
    "    strict=False,\n",
    ")\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Digraph.render?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['PROGRAMFILES']\n",
    "os.environ['CONDA_PREFIX']\n",
    "#C:\\Program Files\\Graphviz 2.44.1\\bin"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "last = 'C:\\\\Users\\\\catch\\\\Anaconda3\\\\envs\\\\p37\\\\Library\\\\bin\\\\graphviz'\n",
    "len(last)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "os.environ[\"PATH\"] = os.environ[\"PATH\"][:-54]\n",
    "os.environ[\"PATH\"][-60:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_gv_envir():\n",
    "    \"\"\" Ad-hoc fix to have Graphiz (v2.38) working on my system. \n",
    "    Note that in case the error ExecutableNotFound occurs, the path to \n",
    "    graphviz must be added to the PATH variable, e.g:\n",
    "    > \"FileNotFoundError: [WinError 2] The system cannot find the file specified\" \n",
    "    > \"ExecutableNotFound: \n",
    "       failed to execute ['dot', '-Tsvg'], make sure the Graphviz executables are\n",
    "       on your systems' PATH\"\n",
    "    The above is not sufficient: the error occurred even though graphviz, dot and\n",
    "    neato are all on my system path.\n",
    "    Calling this function on failed `try` solved the problem. (?)\n",
    "\"\"\"\n",
    "    gviz = os.path.join(os.environ['PROGRAMFILES'], 'Graphviz 2.44.1', 'bin')\n",
    "    os.environ[\"PATH\"] += os.pathsep + gviz\n",
    "    cnd_gv = os.path.join(os.environ['CONDA_PREFIX'], 'Library', 'bin', 'python-graphviz') #'graphviz')\n",
    "    os.environ[\"PATH\"] += os.pathsep + cnd_gv\n",
    "    return gviz, cnd_gv\n",
    "\n",
    "set_gv_envir()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test:\n",
    "gvfile = DIR_IMG.joinpath('tbl.gv')\n",
    "\n",
    "dot_dg = Digraph(comment='The Round Table', filename=gvfile, engine='dot')\n",
    "\n",
    "dot_dg.node('A', 'King Arthur')\n",
    "dot_dg.node('B', 'Sir Bedevere the Wise')\n",
    "dot_dg.node('L', 'Sir Lancelot the Brave')\n",
    "\n",
    "dot_dg.edges(['AB', 'AL'])\n",
    "dot_dg.edge('B', 'L', constraint='false')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dot_dg.render(format='png', view=True)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    ".\n",
    "```\n",
    "# in utils_docs.py:\n",
    "\n",
    "import networkx as nx\n",
    "from networkx.drawing.nx_agraph import graphviz_layout\n",
    "\n",
    "G = nx.DiGraph()\n",
    "\n",
    "G.add_node(\"ROOT\")\n",
    "\n",
    "for i in range(5):\n",
    "    G.add_node(\"Child_%i\" % i)\n",
    "    G.add_node(\"Grandchild_%i\" % i)\n",
    "    G.add_node(\"Greatgrandchild_%i\" % i)\n",
    "\n",
    "    G.add_edge(\"ROOT\", \"Child_%i\" % i)\n",
    "    G.add_edge(\"Child_%i\" % i, \"Grandchild_%i\" % i)\n",
    "    G.add_edge(\"Grandchild_%i\" % i, \"Greatgrandchild_%i\" % i)\n",
    "\n",
    "# write dot file to use with graphviz\n",
    "# run \"dot -Tpng test.dot >test.png\"\n",
    "nx.nx_agraph.write_dot(G,'test.dot')\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "# same layout using matplotlib with no labels\n",
    "plt.title('draw_networkx')\n",
    "pos=graphviz_layout(G, prog='dot')\n",
    "nx.draw(G, pos, with_labels=False, arrows=False)\n",
    "plt.savefig('nx_test.png')\n",
    "#..............\n",
    "\n",
    "import networkx as nx\n",
    "\n",
    "g=nx.DiGraph()\n",
    "g.add_edges_from([(1,2), (1,3), (1,4), (2,5), (2,6), (2,7), (3,8), (3,9),\n",
    "                  (4,10), (5,11), (5,12), (6,13)])\n",
    "p=nx.drawing.nx_pydot.to_pydot(g)\n",
    "p.write_png('example.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtree = {'User Type:':['Admin', 'Tanscriber'],\n",
    "        }"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# test:\n",
    "G = nx.DiGraph()\n",
    "\n",
    "G.add_node(\"ROOT\")\n",
    "\n",
    "for i in range(5):\n",
    "    G.add_node(\"Child_%i\" % i)\n",
    "    G.add_node(\"Grandchild_%i\" % i)\n",
    "    G.add_node(\"Greatgrandchild_%i\" % i)\n",
    "\n",
    "    G.add_edge(\"ROOT\", \"Child_%i\" % i)\n",
    "    G.add_edge(\"Child_%i\" % i, \"Grandchild_%i\" % i)\n",
    "    G.add_edge(\"Grandchild_%i\" % i, \"Greatgrandchild_%i\" % i)\n",
    "\n",
    "pos = nx.drawing.nx_pydot.graphviz_layout(G)\n",
    "nx.draw(G, pos=pos)\n",
    "\n",
    "# write dot file to use with graphviz\n",
    "# run \"dot -Tpng test.dot >test.png\"\n",
    "\n",
    "dotfile = DIR_DATA.joinpath('test.dot')\n",
    "nx.nx_pydot.write_dot(G, dotfile)\n",
    "\n",
    "p = nx.drawing.nx_pydot.to_pydot(G)\n",
    "p"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
