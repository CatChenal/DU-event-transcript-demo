<?xml version="1.0" encoding="utf-8" ?><transcript><text start="1.01" dur="5.769">okay so it&amp;#39;s it&amp;#39;s really great</text><text start="3.57" dur="6">my name is Rashmi Shaikh and I am the</text><text start="6.779" dur="5.521">founder of data umbrella I am also an</text><text start="9.57" dur="6.45">organizer for NYC hi ladies and I am</text><text start="12.3" dur="8.85">based out of New York City welcome to</text><text start="16.02" dur="7.589">our welcome to our session the mission</text><text start="21.15" dur="4.23">of data umbrella is to provide a</text><text start="23.609" dur="4.26">welcoming and educational space for</text><text start="25.38" dur="4.979">underrepresented persons in data science</text><text start="27.869" dur="4.32">we welcome allies to help us in our</text><text start="30.359" dur="5.311">mission and we welcome all different</text><text start="32.189" dur="6.21">skill levels we are on twitter at theta</text><text start="35.67" dur="6.09">umbrella so feel free to tweet and share</text><text start="38.399" dur="5.851">about the event and follow us also</text><text start="41.76" dur="4.709">there&amp;#39;s a LinkedIn page for us where I</text><text start="44.25" dur="3.57">usually share job posting so you&amp;#39;re</text><text start="46.469" dur="3.391">welcome to join there and there&amp;#39;s</text><text start="47.82" dur="6.48">information on the website about a</text><text start="49.86" dur="5.91">discord for community I just want to go</text><text start="54.3" dur="3.09">over the code of conduct that you know</text><text start="55.77" dur="3.9">we&amp;#39;re dedicated to providing harassment</text><text start="57.39" dur="4.29">free experience for everyone be kind to</text><text start="59.67" dur="3.479">others be professional and respectful we</text><text start="61.68" dur="7.59">really want to build a friendly</text><text start="63.149" dur="8.76">community here our Twitter is just to be</text><text start="69.27" dur="6.93">P at data umbrella and also at NYC PI</text><text start="71.909" dur="6.331">ladies and this is our meetup page so</text><text start="76.2" dur="5.07">we&amp;#39;ll be posting I&amp;#39;ll be posting any</text><text start="78.24" dur="4.41">upcoming events on the meetup page even</text><text start="81.27" dur="3.739">though this is webinar and it&amp;#39;s</text><text start="82.65" dur="4.98">available to anybody around the world</text><text start="85.009" dur="7">its meetup pages like the central page</text><text start="87.63" dur="7.529">where the events are posted oh I want to</text><text start="92.009" dur="5.82">thank our speaker she&amp;#39;ll be from joining</text><text start="95.159" dur="5.191">from San Francisco and I want to thank</text><text start="97.829" dur="7.261">our sponsor for providing this webinar</text><text start="100.35" dur="6.03">platform which is neo4j and I&amp;#39;m just</text><text start="105.09" dur="3.69">going to introduce Shelley I actually</text><text start="106.38" dur="4.199">met Shelby back in August in San</text><text start="108.78" dur="4.589">Francisco when I was there for the right</text><text start="110.579" dur="5.851">speak code conference Shelby is the head</text><text start="113.369" dur="4.741">of analytics at Komodo health and as an</text><text start="116.43" dur="3.42">analyst professional and former software</text><text start="118.11" dur="3.63">engineer Shelby has been involved in</text><text start="119.85" dur="4.29">shaping great products or companies big</text><text start="121.74" dur="4.79">and small for the last 13 plus years</text><text start="124.14" dur="5.19">she&amp;#39;s worked on various analyses</text><text start="126.53" dur="5.44">previously she worked at Salesforce and</text><text start="129.33" dur="3.54">she I guess the really impressive thing</text><text start="131.97" dur="3.12">here</text><text start="132.87" dur="4.62">additionally is that she has worked with</text><text start="135.09" dur="15.21">a really large data a data at scale um</text><text start="137.49" dur="14.13">40 million plus users and then I think</text><text start="150.3" dur="6.81">you should be able to screen share now</text><text start="151.62" dur="13.76">don&amp;#39;t get perfect Oh give me a second</text><text start="157.11" dur="8.27">goal all right can you see my screen</text><text start="167.81" dur="12.33">hey I equal to see my screen yes okay</text><text start="176.25" dur="6.21">perfect um okay thank you yeah all right</text><text start="180.14" dur="3.34">anyways thank you all so much for</text><text start="182.46" dur="3">joining in today</text><text start="183.48" dur="3.65">my name is shall give a clue thanks</text><text start="185.46" dur="4.53">again Reshma for the introduction and</text><text start="187.13" dur="5.41">today I am going to walk you all through</text><text start="189.99" dur="5.01">how I think that Sherlock Holmes would</text><text start="192.54" dur="4.47">have fixed back data and I hope you&amp;#39;re</text><text start="195" dur="5.88">all as excited about investigating data</text><text start="197.01" dur="6.93">anomalies as I am so just to pick a</text><text start="200.88" dur="6.03">little bit about me so this is me as a</text><text start="203.94" dur="5.88">child I used to spend a lot of time</text><text start="206.91" dur="4.71">reading detective novels and after I had</text><text start="209.82" dur="4.83">finished reading one I used to go around</text><text start="211.62" dur="5.339">hunting in my backyard for cues I have</text><text start="214.65" dur="4.71">no idea what I was what mystery I was</text><text start="216.959" dur="4.651">trying to solve but one day I found this</text><text start="219.36" dur="4.26">big huge lemon as you can see it&amp;#39;s</text><text start="221.61" dur="3.75">almost the size of my face</text><text start="223.62" dur="4.56">and I didn&amp;#39;t even know we had a lemon</text><text start="225.36" dur="4.53">tree so for my five-year-old for my 11</text><text start="228.18" dur="3.72">year old self this was actually the most</text><text start="229.89" dur="4.92">important discovery I had ever made at</text><text start="231.9" dur="4.5">that point and it just convinced me that</text><text start="234.81" dur="4.89">I&amp;#39;m gonna go on to do very exciting</text><text start="236.4" dur="5.07">things in my future and I don&amp;#39;t think I</text><text start="239.7" dur="3.87">ended up doing some exciting things I</text><text start="241.47" dur="5.25">worked with a lot of different companies</text><text start="243.57" dur="5.19">of different sizes mostly in analytics</text><text start="246.72" dur="4.62">which I&amp;#39;ve been involved in for almost a</text><text start="248.76" dur="6.09">decade but even though I started as an</text><text start="251.34" dur="6.269">engineer and now I am the head of</text><text start="254.85" dur="7.74">analytics at Komodo health where I lead</text><text start="257.609" dur="7.801">a team of eight data scientists so today</text><text start="262.59" dur="3.36">we&amp;#39;re gonna talk about three things one</text><text start="265.41" dur="3.3">what is</text><text start="265.95" dur="8.63">bad data and why should you care about</text><text start="268.71" dur="10.53">it and how do we actually fix it so</text><text start="274.58" dur="6.73">sorry bad data is essentially my</text><text start="279.24" dur="4.76">definition is that it&amp;#39;s inaccurate</text><text start="281.31" dur="4.95">incomplete or misleading data and</text><text start="284" dur="5.53">essentially what that encompasses is</text><text start="286.26" dur="5.79">anything that&amp;#39;s wrong anytime there is</text><text start="289.53" dur="4.32">missing information or there&amp;#39;s duplicate</text><text start="292.05" dur="4.38">information but it&amp;#39;s not actually tagged</text><text start="293.85" dur="4.2">as such or there&amp;#39;s some information or</text><text start="296.43" dur="4.38">data that&amp;#39;s low quality that&amp;#39;s</text><text start="298.05" dur="4.56">incorrectly transformed that can imply</text><text start="300.81" dur="3.99">something different than what what it</text><text start="302.61" dur="5.28">really means all of that comes under the</text><text start="304.8" dur="4.95">umbrella of bad data now this is</text><text start="307.89" dur="3.9">obviously just my definition I&amp;#39;m sure</text><text start="309.75" dur="5.37">what you really want is a scientific</text><text start="311.79" dur="6.3">definition and this is this is the best</text><text start="315.12" dur="4.02">that I came up with bad data is anything</text><text start="318.09" dur="3.72">that makes you want to throw your</text><text start="319.14" dur="7.23">computer across the room because it just</text><text start="321.81" dur="7.59">makes everything terrible so I would</text><text start="326.37" dur="5.7">like to call out that what bad data is</text><text start="329.4" dur="4.77">it is just if it&amp;#39;s not something that</text><text start="332.07" dur="4.29">you want to see or if it&amp;#39;s not something</text><text start="334.17" dur="4.86">that you feel good about like that</text><text start="336.36" dur="4.5">doesn&amp;#39;t make it bad data it&amp;#39;s it still</text><text start="339.03" dur="2.73">has to fit the requirement of it being</text><text start="340.86" dur="3.78">inaccurate</text><text start="341.76" dur="4.68">in some way and just because you don&amp;#39;t</text><text start="344.64" dur="5.46">like what it tells you it doesn&amp;#39;t make</text><text start="346.44" dur="5.73">it bad so with that distinction</text><text start="350.1" dur="5.82">you know let&amp;#39;s actually walk through a</text><text start="352.17" dur="7.29">couple of quick examples of how I think</text><text start="355.92" dur="5.37">bad data actually manifests so one of</text><text start="359.46" dur="5.13">the most common things that I have seen</text><text start="361.29" dur="5.43">is that you know you&amp;#39;re trying to pull</text><text start="364.59" dur="4.68">up revenue numbers because revenue is</text><text start="366.72" dur="4.44">important and you have a sales force</text><text start="369.27" dur="4.26">table that says you made 32 million</text><text start="371.16" dur="4.56">dollars last year and you have an</text><text start="373.53" dur="4.68">internal table that says you made 35</text><text start="375.72" dur="4.49">million dollars so automatically the</text><text start="378.21" dur="4.32">question is well which one is right and</text><text start="380.21" dur="4.36">you know that three million dollar gap</text><text start="382.53" dur="4.65">that is going to decide whether your</text><text start="384.57" dur="4.71">company invests in more snacks for your</text><text start="387.18" dur="4.37">kitchen for example so it&amp;#39;s a really</text><text start="389.28" dur="5.31">important thing to sort of solve for and</text><text start="391.55" dur="4.57">you want to make sure that you trust the</text><text start="394.59" dur="2.85">data that you have and if you don&amp;#39;t</text><text start="396.12" dur="3.51">trust it like you have some caveats</text><text start="397.44" dur="5.02">attached to it and things like that</text><text start="399.63" dur="6.4">the other really common thing that shows</text><text start="402.46" dur="5.94">up is just you know something where the</text><text start="406.03" dur="4.95">analysis just looks really suspicious so</text><text start="408.4" dur="5.49">in the in you know in this new chart you</text><text start="410.98" dur="5.34">can see that you it shows you revenue by</text><text start="413.89" dur="4.26">country and it shows you you have twenty</text><text start="416.32" dur="4.89">five million dollars that you made in UK</text><text start="418.15" dur="4.98">and then you note that you&amp;#39;re actually a</text><text start="421.21" dur="3.51">company that&amp;#39;s located in North America</text><text start="423.13" dur="3.72">you haven&amp;#39;t even ever marketed in Europe</text><text start="424.72" dur="4.8">see all the North American countries</text><text start="426.85" dur="4.68">make sense so you know who are all these</text><text start="429.52" dur="3.72">people in UK who are buying your product</text><text start="431.53" dur="4.38">it just doesn&amp;#39;t make sense that it would</text><text start="433.24" dur="5.13">be the biggest country where you&amp;#39;d have</text><text start="435.91" dur="4.92">revenue from so things like this they</text><text start="438.37" dur="4.23">basically you know are a starting point</text><text start="440.83" dur="5.25">where you start wondering what&amp;#39;s going</text><text start="442.6" dur="4.98">on and you know what is this bad data or</text><text start="446.08" dur="4.2">like where is all this information</text><text start="447.58" dur="7.83">coming from and the next logical</text><text start="450.28" dur="6.93">question that comes up is you know where</text><text start="455.41" dur="5.52">where is this bad data getting created</text><text start="457.21" dur="6.45">created in the first place so for me</text><text start="460.93" dur="5.01">like the way I think about it there is</text><text start="463.66" dur="5.73">essentially a life cycle of data that</text><text start="465.94" dur="6.36">has many phases and each of those phases</text><text start="469.39" dur="5.19">has some inherent risks that are</text><text start="472.3" dur="4.619">associated with it where bad data can be</text><text start="474.58" dur="4.2">introduced so I know there&amp;#39;s a lot of</text><text start="476.919" dur="3.961">information on this slide and I&amp;#39;m going</text><text start="478.78" dur="4.11">to try to break it down I put it as one</text><text start="480.88" dur="5.37">visual because I actually personally</text><text start="482.89" dur="5.16">have this printed out on my desk because</text><text start="486.25" dur="4.2">I like to refer to it just to sort of</text><text start="488.05" dur="3.81">fact check you know any investigation</text><text start="490.45" dur="2.67">that I&amp;#39;m struggling with I try to make</text><text start="491.86" dur="4.5">sure I&amp;#39;m covering my bases</text><text start="493.12" dur="5.91">so say let me let me walk you through</text><text start="496.36" dur="4.83">what&amp;#39;s actually in here so on the on the</text><text start="499.03" dur="6.06">left you see the the five different</text><text start="501.19" dur="5.82">phases of introducing bad data so the</text><text start="505.09" dur="5.81">first one that we start off is is just</text><text start="507.01" dur="6.65">the definition this is where you know</text><text start="510.9" dur="5.35">the data team and the product team are</text><text start="513.66" dur="4.629">reconciling and they&amp;#39;re saying what are</text><text start="516.25" dur="5.43">the features that we even want to</text><text start="518.289" dur="5.341">consider as one coherent unit and then</text><text start="521.68" dur="3.62">what data requirements do we sort of</text><text start="523.63" dur="5.25">associated with it</text><text start="525.3" dur="5.8">after that you go on to login where you</text><text start="528.88" dur="3.69">actually translate some of those</text><text start="531.1" dur="3.18">definitions that</text><text start="532.57" dur="4.86">you had created in the previous step and</text><text start="534.28" dur="7.65">turn them into actual code that you can</text><text start="537.43" dur="6.81">use to log and store that data after</text><text start="541.93" dur="4.95">that you are transforming that data in</text><text start="544.24" dur="4.2">some way and what you&amp;#39;re essentially</text><text start="546.88" dur="4.74">looking at is you&amp;#39;re looking at your</text><text start="548.44" dur="6.78">business rules and you&amp;#39;re applying those</text><text start="551.62" dur="5.37">rules to do that tracked data so that</text><text start="555.22" dur="3.42">you can convert it into a format that</text><text start="556.99" dur="5.7">actually makes sense that is actually</text><text start="558.64" dur="6.81">usable after that comes the fun part</text><text start="562.69" dur="4.71">you&amp;#39;re actually analyzing it so data</text><text start="565.45" dur="3.81">scientists typically they have to</text><text start="567.4" dur="3.84">interpret the data based on you know</text><text start="569.26" dur="4.95">actual business questions that they&amp;#39;re</text><text start="571.24" dur="5.31">trying to solve for and that is that is</text><text start="574.21" dur="5.31">where a lot of the action happens</text><text start="576.55" dur="6.24">and finally after this you actually</text><text start="579.52" dur="4.98">share out your results and it can happen</text><text start="582.79" dur="3.9">in a bunch of different ways it can</text><text start="584.5" dur="5.34">happen in the way of an ad hoc analysis</text><text start="586.69" dur="5.4">or some some self-service reports things</text><text start="589.84" dur="5.18">like that and all of these these things</text><text start="592.09" dur="6.12">are shared directly with stakeholders so</text><text start="595.02" dur="4.81">during all of these phases I&amp;#39;ve you know</text><text start="598.21" dur="4.62">on the on the right I&amp;#39;ve kind of</text><text start="599.83" dur="5.13">highlighted a few common things that I</text><text start="602.83" dur="3.81">observe in each of the phases like which</text><text start="604.96" dur="4.83">are just according to me they&amp;#39;re the</text><text start="606.64" dur="4.35">most they&amp;#39;re the most logical places</text><text start="609.79" dur="3.24">where something goes wrong</text><text start="610.99" dur="4.62">so I actually look at all of these</text><text start="613.03" dur="4.08">things just as a as a sanity check when</text><text start="615.61" dur="3.27">I&amp;#39;m trying to investigate what happened</text><text start="617.11" dur="4.02">I&amp;#39;m going to walk you through a couple</text><text start="618.88" dur="4.17">of them I won&amp;#39;t walk you through all but</text><text start="621.13" dur="4.79">because some of them I&amp;#39;ll be discussing</text><text start="623.05" dur="5.25">later when I&amp;#39;m talking about fixes so</text><text start="625.92" dur="4.99">you know some of the most obvious ones</text><text start="628.3" dur="7.59">all most common ones that I see is</text><text start="630.91" dur="6.39">actually in the definition stage so you</text><text start="635.89" dur="3.81">know when we when we think about</text><text start="637.3" dur="4.83">features anything that we are trying to</text><text start="639.7" dur="5.07">track it has some sort of a definition</text><text start="642.13" dur="5.1">associated with it and how we define</text><text start="644.77" dur="4.56">that feature can make a lot of</text><text start="647.23" dur="5.4">difference in to what insights they&amp;#39;re</text><text start="649.33" dur="6.87">able to get from it at a later stage so</text><text start="652.63" dur="6.33">if you don&amp;#39;t evenly apply the same you</text><text start="656.2" dur="4.89">know same sort of intention behind some</text><text start="658.96" dur="4.65">of these feature definitions it can get</text><text start="661.09" dur="5.48">quite confusing later on so an example</text><text start="663.61" dur="2.96">here is that let&amp;#39;s say you</text><text start="666.64" dur="6">you know your product team says I want</text><text start="669.22" dur="5.85">to track all clicks on this page any</text><text start="672.64" dur="3.09">click that happens I want to check it so</text><text start="675.07" dur="2.9">that&amp;#39;s so pretty</text><text start="675.73" dur="6.81">like it&amp;#39;s a pretty all-encompassing</text><text start="677.97" dur="6.55">definition but you also have you know as</text><text start="682.54" dur="4.77">a team that&amp;#39;s dedicated to tracking</text><text start="684.52" dur="4.56">things that occur on mobile and so in</text><text start="687.31" dur="3.69">mobile environment they&amp;#39;ll be like yeah</text><text start="689.08" dur="3.87">I want to track the chicks there too so</text><text start="691" dur="5.64">initially you logically think that all</text><text start="692.95" dur="6.09">my all my clicks on the on the website</text><text start="696.64" dur="4.14">are being tracked and some some subset</text><text start="699.04" dur="6.09">of them would have happened on the</text><text start="700.78" dur="7.23">mobile but if mobile team decides to not</text><text start="705.13" dur="4.23">track all the clicks and only like three</text><text start="708.01" dur="4.14">of the buttons that you can possibly</text><text start="709.36" dur="5.73">click then you have definitions that are</text><text start="712.15" dur="6.12">not evenly aligned because you&amp;#39;d assume</text><text start="715.09" dur="5.61">that you know the the website clicks are</text><text start="718.27" dur="5.61">still kind of the superset of everything</text><text start="720.7" dur="6.18">but you&amp;#39;d expect that the mobile subset</text><text start="723.88" dur="5.82">is a full subset for all mobile clicks</text><text start="726.88" dur="5.4">but it&amp;#39;s actually only tracking three</text><text start="729.7" dur="6.84">three types of clicks so that can cause</text><text start="732.28" dur="6.24">issues because anybody who&amp;#39;s done this</text><text start="736.54" dur="3.84">long enough knows that they&amp;#39;ll always be</text><text start="738.52" dur="3.84">that one person who&amp;#39;ll say I want that</text><text start="740.38" dur="3.99">one click on mobile that nobody&amp;#39;s</text><text start="742.36" dur="3.24">tracking like give me information on</text><text start="744.37" dur="2.46">that like you know you&amp;#39;re giving me</text><text start="745.6" dur="3.69">information about everything else what</text><text start="746.83" dur="5.07">about that one so the more thoughtful</text><text start="749.29" dur="4.38">you are upfront about like making sure</text><text start="751.9" dur="3.54">you&amp;#39;re tracking everything evenly it&amp;#39;ll</text><text start="753.67" dur="6.66">it&amp;#39;ll just be easier in the in the long</text><text start="755.44" dur="7.71">run the other example is at the analysis</text><text start="760.33" dur="4.32">phase so you know I think that&amp;#39;s again</text><text start="763.15" dur="4.5">one of the most common things that</text><text start="764.65" dur="6.3">happen that you just don&amp;#39;t define the</text><text start="767.65" dur="6.93">problem it&amp;#39;s it&amp;#39;s very ambiguous because</text><text start="770.95" dur="6.72">especially when we&amp;#39;re you know one human</text><text start="774.58" dur="5.01">talking to another human you know you&amp;#39;re</text><text start="777.67" dur="3.51">two separate humans so you&amp;#39;re always</text><text start="779.59" dur="3.06">gonna have some things that you&amp;#39;re not</text><text start="781.18" dur="4.92">where you&amp;#39;re not aligned where you don&amp;#39;t</text><text start="782.65" dur="5.28">understand each other and you know if</text><text start="786.1" dur="3.6">you&amp;#39;re talking to a product manager they</text><text start="787.93" dur="3.48">can make certain assumptions that like</text><text start="789.7" dur="4.41">oh I&amp;#39;m sure they already know this and</text><text start="791.41" dur="4.56">then you can make certain assumptions</text><text start="794.11" dur="4.8">like oh I already like of course they</text><text start="795.97" dur="4.9">know that this can&amp;#39;t happen so if you</text><text start="798.91" dur="4.99">don&amp;#39;t actually clarify some of those</text><text start="800.87" dur="6.59">that can result in some very tough</text><text start="803.9" dur="6.24">consequences you know you may end up</text><text start="807.46" dur="5.08">spending a lot of time doing some work</text><text start="810.14" dur="3.93">which has to be redone because there was</text><text start="812.54" dur="3.66">an incorrect assumption in the first</text><text start="814.07" dur="4.05">place or worse</text><text start="816.2" dur="4.02">maybe the error never gets discovered</text><text start="818.12" dur="3.48">because you are all you&amp;#39;re both calling</text><text start="820.22" dur="2.34">in the same thing but you&amp;#39;re actually</text><text start="821.6" dur="5.91">doing something that&amp;#39;s completely</text><text start="822.56" dur="6.96">different so these type of examples you</text><text start="827.51" dur="3.81">know you can you can kind of look</text><text start="829.52" dur="3.66">through the remaining ones later but</text><text start="831.32" dur="6.53">these are some common things that kind</text><text start="833.18" dur="7.56">of show up all right so why should</text><text start="837.85" dur="4.87">organizations or you know anybody even</text><text start="840.74" dur="5.48">care about all this bad data now that</text><text start="842.72" dur="7.38">we&amp;#39;ve seen a couple of ways it showed up</text><text start="846.22" dur="6.18">so I think inherently the big takeaway</text><text start="850.1" dur="6.09">that I have seen over the years is that</text><text start="852.4" dur="6.4">bad data is just costly it&amp;#39;s costly at</text><text start="856.19" dur="5.76">every single level across the company I</text><text start="858.8" dur="5.22">think you know to start with the people</text><text start="861.95" dur="4.8">who are working who have to deal with it</text><text start="864.02" dur="5.34">it is it hampers their productivity</text><text start="866.75" dur="4.47">if you don&amp;#39;t upfront spend that time and</text><text start="869.36" dur="4.56">effort in trying to keep things clean</text><text start="871.22" dur="4.89">and it affects our morale because they</text><text start="873.92" dur="3.99">feel that you know this is this is just</text><text start="876.11" dur="4.83">I spend so much time doing something I</text><text start="877.91" dur="5.13">don&amp;#39;t want to do it can also affect it</text><text start="880.94" dur="4.08">can cause liabilities you can sometimes</text><text start="883.04" dur="4.71">end up sharing information that you had</text><text start="885.02" dur="4.71">you&amp;#39;re not supposed to or you shared</text><text start="887.75" dur="5.34">incorrect information that&amp;#39;s specially a</text><text start="889.73" dur="5.76">problem if if you&amp;#39;re a public traded</text><text start="893.09" dur="4.92">publicly traded company and you had an</text><text start="895.49" dur="5.52">earnings call where you said I have you</text><text start="898.01" dur="5.55">know X number of monthly active users</text><text start="901.01" dur="4.65">and then the next earnings call you&amp;#39;re</text><text start="903.56" dur="4.92">like well just kidding it&amp;#39;s actually 20%</text><text start="905.66" dur="4.53">lower because I made a mistake that&amp;#39;s</text><text start="908.48" dur="4.26">not gonna look good and you might your</text><text start="910.19" dur="6.33">company might actually get sued for for</text><text start="912.74" dur="6.72">misleading shareholders so bias of</text><text start="916.52" dur="5.13">course is a big problem you know if you</text><text start="919.46" dur="4.44">if you have some if you have some data</text><text start="921.65" dur="4.65">that&amp;#39;s inherently biased and that&amp;#39;s not</text><text start="923.9" dur="4.83">known to you like that&amp;#39;s just it&amp;#39;s it&amp;#39;s</text><text start="926.3" dur="4.83">it&amp;#39;s a it&amp;#39;s it&amp;#39;s a it&amp;#39;s a issue because</text><text start="928.73" dur="4.74">it can cause harm to people based on</text><text start="931.13" dur="3.209">whatever decisions are being made with</text><text start="933.47" dur="4.2">that data</text><text start="934.339" dur="5.79">and overall you know you can also just</text><text start="937.67" dur="4.44">straight-up lose revenue so if you have</text><text start="940.129" dur="4.38">a bad data pipeline and data goes</text><text start="942.11" dur="4.709">missing maybe your marketing team</text><text start="944.509" dur="4.44">doesn&amp;#39;t have leads to follow up on and</text><text start="946.819" dur="5.731">that can lead to material revenue</text><text start="948.949" dur="6.3">revenue costs overall I think the</text><text start="952.55" dur="4.889">biggest the biggest reason that I think</text><text start="955.249" dur="5.611">this is important is also because it</text><text start="957.439" dur="5.46">lowers trust the minute your customers</text><text start="960.86" dur="4.8">find out that there is something sketchy</text><text start="962.899" dur="5.281">going on with your data that can often</text><text start="965.66" dur="3.989">be just game over for you because if</text><text start="968.18" dur="6.959">they do if they don&amp;#39;t trust your data</text><text start="969.649" dur="7.831">they don&amp;#39;t it had a really trust you the</text><text start="975.139" dur="4.11">one thing that I again like to sort of</text><text start="977.48" dur="4.14">highlight a little bit more is that I</text><text start="979.249" dur="4.411">think you know besides all those other</text><text start="981.62" dur="4.8">reasons which have a cost attached to it</text><text start="983.66" dur="5.219">I think just the fact that data</text><text start="986.42" dur="4.829">scientists have no moral because it&amp;#39;s</text><text start="988.879" dur="4.89">something like this is reason enough for</text><text start="991.249" dur="5.64">people to care about it you know data</text><text start="993.769" dur="5.01">scientists have to find the error find</text><text start="996.889" dur="4.04">the source validate cross checking it so</text><text start="998.779" dur="5.31">it&amp;#39;s a lot of work that goes into</text><text start="1000.929" dur="6.01">resolving some of these issues and I</text><text start="1004.089" dur="4.86">think inherently it very much is a part</text><text start="1006.939" dur="4.02">of a data scientist job to do this but</text><text start="1008.949" dur="4.171">inherently they feel well my skills are</text><text start="1010.959" dur="5.36">so much you know there&amp;#39;s so much other</text><text start="1013.12" dur="6.149">cool stuff that I can be doing and so</text><text start="1016.319" dur="4.99">everyone wants to be they everyone wants</text><text start="1019.269" dur="4.201">their talents to be used in an optimal</text><text start="1021.309" dur="4.441">way and you don&amp;#39;t want people leaving</text><text start="1023.47" dur="6.319">leaving a job just because they&amp;#39;re</text><text start="1025.75" dur="9.659">always dealing with dirty data issues so</text><text start="1029.789" dur="10.691">good so next you know how do we actually</text><text start="1035.409" dur="6.9">solve it my my thought here is I think I</text><text start="1040.48" dur="5.16">think we solve it by thinking like</text><text start="1042.309" dur="5.85">Sherlock Holmes and for for those of you</text><text start="1045.64" dur="4.86">who are not familiar with him Sherlock</text><text start="1048.159" dur="5.461">Holmes is a fictitious character created</text><text start="1050.5" dur="4.89">by Sir Arthur Conan Doyle he is arguably</text><text start="1053.62" dur="4.11">one of the most famous fictional</text><text start="1055.39" dur="4.71">detectives and there&amp;#39;s a lot of books</text><text start="1057.73" dur="4.59">and movies about like that character so</text><text start="1060.1" dur="5.64">check it out if you haven&amp;#39;t had the</text><text start="1062.32" dur="5.28">chance to so why did I actually pick</text><text start="1065.74" dur="4.74">Sherlock Holmes</text><text start="1067.6" dur="6.959">for you know why did I pick that we</text><text start="1070.48" dur="6.78">should emulate his his style so I</text><text start="1074.559" dur="5.071">actually think that his style of solving</text><text start="1077.26" dur="4.5">crimes is very relevant to data</text><text start="1079.63" dur="4.83">scientists even though hopefully we&amp;#39;re</text><text start="1081.76" dur="5.159">not solving crimes just data issues but</text><text start="1084.46" dur="5.459">I think inherently we&amp;#39;re doing</text><text start="1086.919" dur="6.031">investigations and I think a lot of his</text><text start="1089.919" dur="5.281">personality traits are very good if you</text><text start="1092.95" dur="4.56">think of a philosophy of how data</text><text start="1095.2" dur="5.43">scientist should think I think it&amp;#39;s very</text><text start="1097.51" dur="5.37">it&amp;#39;s it&amp;#39;s it&amp;#39;s a it&amp;#39;s very relevant and</text><text start="1100.63" dur="3.9">inherently Sherlock Holmes is always</text><text start="1102.88" dur="4.23">presented as a very very data-driven</text><text start="1104.53" dur="5.97">character so I think his methodologies</text><text start="1107.11" dur="5.939">are actually extremely relevant and the</text><text start="1110.5" dur="5.58">three sort of traits of his that I</text><text start="1113.049" dur="6.541">picked which are sort of you know larger</text><text start="1116.08" dur="6.69">bucketing of of some of his personality</text><text start="1119.59" dur="7.62">are deep observation scientific method</text><text start="1122.77" dur="6.57">and pattern matching so let&amp;#39;s dive into</text><text start="1127.21" dur="8.43">a little bit of each of these and see</text><text start="1129.34" dur="8.73">how they sort of manifest so his deep</text><text start="1135.64" dur="4.529">observation is so there&amp;#39;s a very famous</text><text start="1138.07" dur="6.239">quote that Sherlock Holmes says in one</text><text start="1140.169" dur="7.591">of the books he says he says you see but</text><text start="1144.309" dur="6.031">you do not observe and that&amp;#39;s a that&amp;#39;s a</text><text start="1147.76" dur="6.049">that&amp;#39;s a very interesting difference</text><text start="1150.34" dur="5.969">distinction to call out that if</text><text start="1153.809" dur="6.131">essentially when we have data in front</text><text start="1156.309" dur="6.421">of us our default is to look at it and</text><text start="1159.94" dur="5.58">absorb the information ances but when we</text><text start="1162.73" dur="6.12">actually start observing it more closely</text><text start="1165.52" dur="6.09">we gain more nuance by just interacting</text><text start="1168.85" dur="5.52">with that information as an active</text><text start="1171.61" dur="6.15">participant and that is a skill that I</text><text start="1174.37" dur="4.89">think is worth building on so some of</text><text start="1177.76" dur="5.52">the ways that you can build on that</text><text start="1179.26" dur="8.549">skill is to just be fully present and</text><text start="1183.28" dur="6.629">very mindful so when you&amp;#39;re mindfully</text><text start="1187.809" dur="4.411">interacting with not just the person who</text><text start="1189.909" dur="3.781">you know your stakeholder your your</text><text start="1192.22" dur="2.97">business partner like people like that</text><text start="1193.69" dur="4.02">like when you&amp;#39;re mindfully interacting</text><text start="1195.19" dur="5.219">with them you&amp;#39;re more engaged you are</text><text start="1197.71" dur="3.41">not going to be distracted and that will</text><text start="1200.409" dur="2.931">mean that</text><text start="1201.12" dur="6.06">don&amp;#39;t you don&amp;#39;t miss out on something</text><text start="1203.34" dur="6.09">that&amp;#39;s critical for you to you know be</text><text start="1207.18" dur="3.69">able to solve the problem at hand and I</text><text start="1209.43" dur="5.07">think it&amp;#39;s one of the best ways to have</text><text start="1210.87" dur="5.52">impact the other way to improve your</text><text start="1214.5" dur="3.99">observation is to be an active</text><text start="1216.39" dur="6.63">participant in with whatever you&amp;#39;re</text><text start="1218.49" dur="6.03">doing so you know one of the you know</text><text start="1223.02" dur="4.14">one of the fun examples that they called</text><text start="1224.52" dur="4.68">out is that you know when Sherlock</text><text start="1227.16" dur="4.14">Holmes was given you know he said they</text><text start="1229.2" dur="4.2">said oh here we found this note and this</text><text start="1231.3" dur="2.82">is a clue so he didn&amp;#39;t actually just</text><text start="1233.4" dur="3.21">read it</text><text start="1234.12" dur="4.92">he didn&amp;#39;t just like you know look at it</text><text start="1236.61" dur="4.17">he he actually smelt it too because he</text><text start="1239.04" dur="4.35">said you know smelling it is gonna give</text><text start="1240.78" dur="5.31">me some extra insight and I just reading</text><text start="1243.39" dur="5.039">it doesn&amp;#39;t doesn&amp;#39;t gave me and that is a</text><text start="1246.09" dur="4.98">very interesting thing because you&amp;#39;re</text><text start="1248.429" dur="4.201">you know you&amp;#39;re actively participating</text><text start="1251.07" dur="3.239">with the information in front of you</text><text start="1252.63" dur="3.81">you&amp;#39;re you&amp;#39;re being inclusive you&amp;#39;re not</text><text start="1254.309" dur="4.471">just saying well this is how I normally</text><text start="1256.44" dur="4.41">look at data but like you&amp;#39;re trying to</text><text start="1258.78" dur="4.2">be you&amp;#39;re trying to be thoughtful and</text><text start="1260.85" dur="5.28">getting into the weeds of how you can</text><text start="1262.98" dur="8.22">use use information in in in to tell you</text><text start="1266.13" dur="7.29">different insights the next thing again</text><text start="1271.2" dur="5.609">about improving your observation is to</text><text start="1273.42" dur="7.2">structure your thinking so this one is</text><text start="1276.809" dur="5.731">you know I think like all good engineers</text><text start="1280.62" dur="3.48">have to do it you have to just be</text><text start="1282.54" dur="3.6">structured you have to keep good</text><text start="1284.1" dur="3.51">documentation I think for data</text><text start="1286.14" dur="4.53">scientists it&amp;#39;s especially relevant</text><text start="1287.61" dur="5.13">because you know sometimes during our</text><text start="1290.67" dur="6.54">analysis we&amp;#39;ll make some assumptions and</text><text start="1292.74" dur="6.66">if it&amp;#39;s not or we&amp;#39;ll make some decisions</text><text start="1297.21" dur="3.84">rather and if it&amp;#39;s not an intuitive</text><text start="1299.4" dur="2.25">decision like why did we make that</text><text start="1301.05" dur="2.7">decision</text><text start="1301.65" dur="5.19">maybe we made it because we spoke to a</text><text start="1303.75" dur="4.98">colleague who pointed something out and</text><text start="1306.84" dur="4.14">if two months later we&amp;#39;d forget why we</text><text start="1308.73" dur="4.949">why we decided to go this direction with</text><text start="1310.98" dur="4.44">our analysis it will be really helpful</text><text start="1313.679" dur="4.261">to you if you have actually sort of</text><text start="1315.42" dur="3.99">documented that somewhere so that even</text><text start="1317.94" dur="3.39">you yourself are not struggling with</text><text start="1319.41" dur="6.78">figuring out why you why you did</text><text start="1321.33" dur="6.42">something specific so you know and and</text><text start="1326.19" dur="4.53">like being structured also means that</text><text start="1327.75" dur="5.429">you you try to look at information and</text><text start="1330.72" dur="4.14">sift through it and say like you know</text><text start="1333.179" dur="3.511">let me step back and</text><text start="1334.86" dur="3.51">what is actually useful to me what is</text><text start="1336.69" dur="3.51">just a red herring or something that&amp;#39;s</text><text start="1338.37" dur="6.48">kind of taking me away from what I&amp;#39;m</text><text start="1340.2" dur="7.19">actually trying to do here the next</text><text start="1344.85" dur="8.07">character trait was scientific method</text><text start="1347.39" dur="7.18">and here again you know the famous quote</text><text start="1352.92" dur="3.81">here is when you have eliminated the</text><text start="1354.57" dur="5.37">impossible whatever remains however</text><text start="1356.73" dur="5.43">improbable must be the truth it&amp;#39;s a very</text><text start="1359.94" dur="5.31">it&amp;#39;s a very scientific way of thinking</text><text start="1362.16" dur="5.37">about it cuz we you know we have to</text><text start="1365.25" dur="4.95">regard facts as truth even if we can&amp;#39;t</text><text start="1367.53" dur="5.34">see it and if the most likely answer is</text><text start="1370.2" dur="3.69">not the answer and the impossible answer</text><text start="1372.87" dur="4.86">is not the answer</text><text start="1373.89" dur="5.82">we have to give the improbable answer a</text><text start="1377.73" dur="4.319">chance to prove itself and we have to be</text><text start="1379.71" dur="4.23">truthful saying that if this is where</text><text start="1382.049" dur="2.521">things are pointing me I have to give it</text><text start="1383.94" dur="2.82">a shot</text><text start="1384.57" dur="6.359">to sort of see if that&amp;#39;s actually true</text><text start="1386.76" dur="6.57">or not so here again you know you can</text><text start="1390.929" dur="5.761">build on this scale by just generally</text><text start="1393.33" dur="6.33">avoided avoiding the trap of bias and I</text><text start="1396.69" dur="4.95">think you know a lot of times it&amp;#39;s it&amp;#39;s</text><text start="1399.66" dur="6.269">very easy like it&amp;#39;s human nature that we</text><text start="1401.64" dur="6.06">are the if we&amp;#39;re given if you&amp;#39;re given</text><text start="1405.929" dur="4.021">something that makes our life easier so</text><text start="1407.7" dur="5.25">someone States an opinion which sounds</text><text start="1409.95" dur="6.479">kind of correct like it makes our brain</text><text start="1412.95" dur="6.719">is programmed to just attach to it</text><text start="1416.429" dur="4.351">because it makes our life easier so but</text><text start="1419.669" dur="2.871">we should we should you know</text><text start="1420.78" dur="5.58">purposefully step away from that because</text><text start="1422.54" dur="6.67">a lot of times opinions are stated as</text><text start="1426.36" dur="4.62">facts and people then there must have</text><text start="1429.21" dur="4.02">been tons of companies that you know</text><text start="1430.98" dur="3.63">said hey our monthly active users just</text><text start="1433.23" dur="4.71">never go down like we&amp;#39;re a growing</text><text start="1434.61" dur="5.64">company and then coronavirus hit and of</text><text start="1437.94" dur="5.43">course a lot of companies lost lost</text><text start="1440.25" dur="4.77">users and if they had treated that as a</text><text start="1443.37" dur="4.08">fact that like there&amp;#39;s just no way that</text><text start="1445.02" dur="4.74">we can ever have less people coming to</text><text start="1447.45" dur="5.43">our site you know they would have just</text><text start="1449.76" dur="5.25">found it way harder to be like well you</text><text start="1452.88" dur="4.38">know why is this happening now of course</text><text start="1455.01" dur="3.75">in this example I&amp;#39;m assuming people</text><text start="1457.26" dur="3.39">weren&amp;#39;t living under a rock and they</text><text start="1458.76" dur="3.659">kind of heard about the covert situation</text><text start="1460.65" dur="3.63">so hopefully they would have been able</text><text start="1462.419" dur="3.51">to piece things together but you know</text><text start="1464.28" dur="4.38">there could be some situations there you</text><text start="1465.929" dur="4.651">just don&amp;#39;t know what&amp;#39;s going on</text><text start="1468.66" dur="5.19">and the other thing sharer is you know</text><text start="1470.58" dur="5.28">we tend to the information that is</text><text start="1473.85" dur="4.89">available to us like the information</text><text start="1475.86" dur="4.8">that&amp;#39;s in front of us that we can see we</text><text start="1478.74" dur="4.65">tend to weigh that more heavily than</text><text start="1480.66" dur="6.12">what we don&amp;#39;t have access to so for</text><text start="1483.39" dur="6.78">example if I have access to the signups</text><text start="1486.78" dur="6.78">that occurred on my website but I don&amp;#39;t</text><text start="1490.17" dur="5.67">have access to the actual you know</text><text start="1493.56" dur="4.95">volume of people who came to my site and</text><text start="1495.84" dur="5.4">bounced out without signing up I will</text><text start="1498.51" dur="4.32">just look at my signups and be like yeah</text><text start="1501.24" dur="3.21">it&amp;#39;s going really well</text><text start="1502.83" dur="4.38">you know I&amp;#39;m I have so many people</text><text start="1504.45" dur="6.24">coming to my site but the fact is while</text><text start="1507.21" dur="6.39">that singularly might be true if you</text><text start="1510.69" dur="5.79">just have had a lot more people come and</text><text start="1513.6" dur="5.04">yes overall your signups are going going</text><text start="1516.48" dur="5.16">higher but your rate of conversion is</text><text start="1518.64" dur="4.83">actually lowering your you&amp;#39;re missing</text><text start="1521.64" dur="3.3">out on key information by like just</text><text start="1523.47" dur="5.42">being biased towards the information</text><text start="1524.94" dur="3.95">that&amp;#39;s available to you at that point</text><text start="1529.34" dur="5.98">and then you know the last way to build</text><text start="1531.96" dur="5.49">this skill is to you know regular</text><text start="1535.32" dur="5.25">science facts like build a hypothesis</text><text start="1537.45" dur="5.67">test it out if you have multiple</text><text start="1540.57" dur="4.98">multiple options to go with you rank</text><text start="1543.12" dur="4.92">them pick the most likely one first to</text><text start="1545.55" dur="4.86">test out and keep kind of validating</text><text start="1548.04" dur="4.32">each of them until you find something</text><text start="1550.41" dur="7.17">that fully explains what issues you</text><text start="1552.36" dur="9.12">might be having the last skill was about</text><text start="1557.58" dur="5.34">pattern matching so you know there is</text><text start="1561.48" dur="4.41">nothing more deceptive that an obvious</text><text start="1562.92" dur="5.67">fact as Sherlock Holmes said and it&amp;#39;s</text><text start="1565.89" dur="3.81">it&amp;#39;s it&amp;#39;s because you know the</text><text start="1568.59" dur="3">interesting thing was Holmes was</text><text start="1569.7" dur="3.71">actually considered to be very good at</text><text start="1571.59" dur="4.23">understanding human behavior and</text><text start="1573.41" dur="3.67">predicting human behavior even though he</text><text start="1575.82" dur="3.78">was considered someone who wasn&amp;#39;t</text><text start="1577.08" dur="4.68">actually very good at empathizing and I</text><text start="1579.6" dur="5.46">and that may seem you know not very</text><text start="1581.76" dur="6.33">aligned but the sheer fact is that when</text><text start="1585.06" dur="5.46">you understand when you understand</text><text start="1588.09" dur="4.13">situations people all of that better you</text><text start="1590.52" dur="5.25">are much more easily able to find</text><text start="1592.22" dur="6.7">patterns and you know that hey this may</text><text start="1595.77" dur="5.4">present as an obvious fact but it&amp;#39;s very</text><text start="1598.92" dur="3.42">common for people to sort of you know</text><text start="1601.17" dur="2.67">stated as a fact but</text><text start="1602.34" dur="5.1">it&amp;#39;s not it&amp;#39;s not true so like let me</text><text start="1603.84" dur="6.63">dig into it a little bit more so a good</text><text start="1607.44" dur="4.8">way to improve on this skill is just to</text><text start="1610.47" dur="4.92">be very objective when you&amp;#39;re trying to</text><text start="1612.24" dur="4.41">parse information you know understand</text><text start="1615.39" dur="3.45">the people that you&amp;#39;re dealing with</text><text start="1616.65" dur="4.11">understand their motivations understand</text><text start="1618.84" dur="2.969">that fears those things could be very</text><text start="1620.76" dur="4.98">different than yours</text><text start="1621.809" dur="5.401">so if you have stakeholders you know if</text><text start="1625.74" dur="3.84">you have a product person and a</text><text start="1627.21" dur="4.709">marketing person for both coming and</text><text start="1629.58" dur="4.56">telling you this data looks wrong they</text><text start="1631.919" dur="5.071">might have very different opinions on</text><text start="1634.14" dur="6.36">where they think the problem occurs and</text><text start="1636.99" dur="6.929">you have to still separate yourself from</text><text start="1640.5" dur="5.34">you know from from sort of those two</text><text start="1643.919" dur="4.26">conflicting conflicting directions and</text><text start="1645.84" dur="5.4">pick what what makes the most sense for</text><text start="1648.179" dur="4.651">you to investigate first because you</text><text start="1651.24" dur="3.27">because you know otherwise you won&amp;#39;t be</text><text start="1652.83" dur="5.16">objective and you won&amp;#39;t you won&amp;#39;t stay</text><text start="1654.51" dur="4.86">focused on the truth say as you hear as</text><text start="1657.99" dur="3.6">you hear opinions and ideas I guess</text><text start="1659.37" dur="4.83">always good to understand that also for</text><text start="1661.59" dur="6.9">future reference but try to sort of like</text><text start="1664.2" dur="5.94">parse the right information from it the</text><text start="1668.49" dur="4.77">last way to sort of improve on that</text><text start="1670.14" dur="6.269">skill is to just in general widen your</text><text start="1673.26" dur="4.62">knowledge base so you know as as a data</text><text start="1676.409" dur="3.99">scientist I think it&amp;#39;s extremely</text><text start="1677.88" dur="5.88">important that like obviously we have to</text><text start="1680.399" dur="5.821">get really good at understanding the</text><text start="1683.76" dur="5.94">data appreciating what it does but the</text><text start="1686.22" dur="6.179">other part is like if you if you do an</text><text start="1689.7" dur="5.209">equally good job at also understanding</text><text start="1692.399" dur="4.861">the product understanding the users</text><text start="1694.909" dur="4.12">understanding how your marketing channel</text><text start="1697.26" dur="4.11">works and things like that it can</text><text start="1699.029" dur="4.981">actually allow you to make a hypothesis</text><text start="1701.37" dur="5.22">much more easily when you sees things</text><text start="1704.01" dur="4.08">that are going wrong and you&amp;#39;d be in a</text><text start="1706.59" dur="3.78">better position because you would have</text><text start="1708.09" dur="4.199">seen some odd things that happen which</text><text start="1710.37" dur="4.38">if you just focused on the data you</text><text start="1712.289" dur="4.951">wouldn&amp;#39;t have access to so it it</text><text start="1714.75" dur="5.25">basically allows you to consider you</text><text start="1717.24" dur="7.97">know factors outside of just just what&amp;#39;s</text><text start="1720" dur="7.76">in what&amp;#39;s in front of you all right so</text><text start="1725.21" dur="4.78">hopefully they&amp;#39;re all made sense so far</text><text start="1727.76" dur="5.35">now we are actually going to walk</text><text start="1729.99" dur="4.919">through an example so you know we</text><text start="1733.11" dur="2.89">hopefully we understand a little bit how</text><text start="1734.909" dur="3.49">Sherlock Holmes</text><text start="1736" dur="4.889">and how we can apply his mindset to our</text><text start="1738.399" dur="3.601">own problem-solving techniques so now</text><text start="1740.889" dur="3.51">I&amp;#39;m going to walk through a simple</text><text start="1742" dur="4.169">example where we will try to use some of</text><text start="1744.399" dur="4.53">those philosophies that I kind of just</text><text start="1746.169" dur="6.24">highlighted and for the sake of</text><text start="1748.929" dur="6.09">simplicity I am going to go with the</text><text start="1752.409" dur="4.801">assumption that we eventually have one</text><text start="1755.019" dur="3.691">warehouse where we store all our data</text><text start="1757.21" dur="3.839">regardless of where it comes from</text><text start="1758.71" dur="4.679">so whether it&amp;#39;s initially coming from</text><text start="1761.049" dur="5.13">Salesforce heap website logs whatever</text><text start="1763.389" dur="5.16">all of it comes and it sits in one data</text><text start="1766.179" dur="4.71">warehouses I want to make life my life</text><text start="1768.549" dur="6.931">easier and just compare two data sets in</text><text start="1770.889" dur="6.78">the same place so this is this is</text><text start="1775.48" dur="6.6">typically how they how the question</text><text start="1777.669" dur="7.49">starts and I I hope a lot of you can</text><text start="1782.08" dur="5.4">relate to this specific example which is</text><text start="1785.159" dur="3.791">you know you have a colleague maybe</text><text start="1787.48" dur="3.51">they&amp;#39;re in marketing or something and</text><text start="1788.95" dur="6.75">they come to you with the question they</text><text start="1790.99" dur="6.75">say the number of sales in May I pulled</text><text start="1795.7" dur="4.349">one number from Salesforce report and</text><text start="1797.74" dur="4.919">today they reported something else in</text><text start="1800.049" dur="4.86">all hands and you know what&amp;#39;s the deal</text><text start="1802.659" dur="4.411">why they why they&amp;#39;re not matching so</text><text start="1804.909" dur="5.161">obviously a lot of things could have</text><text start="1807.07" dur="4.589">gone wrong and for the purpose of this</text><text start="1810.07" dur="2.79">example we are actually going to pretend</text><text start="1811.659" dur="5.551">everything that could go wrong did</text><text start="1812.86" dur="7.649">indeed go wrong and yeah I like that you</text><text start="1817.21" dur="4.829">know of course if you&amp;#39;ve been at a</text><text start="1820.509" dur="3.361">company for a while or if you&amp;#39;ve</text><text start="1822.039" dur="3.99">interacted with that same data set for a</text><text start="1823.87" dur="4.35">long time you&amp;#39;d probably have you&amp;#39;d</text><text start="1826.029" dur="5.4">probably start building out a good idea</text><text start="1828.22" dur="6.6">of where the problem might be but for</text><text start="1831.429" dur="5.311">this example yeah for this example I am</text><text start="1834.82" dur="3.959">going to assume that you just joined two</text><text start="1836.74" dur="4.169">hours ago you know no one you know</text><text start="1838.779" dur="4.14">nothing all you know is your snowflake</text><text start="1840.909" dur="5.97">warehouse password and what the</text><text start="1842.919" dur="7.62">offending data sets are so before we</text><text start="1846.879" dur="7.951">begin actual coding some simple sanity</text><text start="1850.539" dur="6.531">check lists to just examine the facts we</text><text start="1854.83" dur="5.339">are talking about two different numbers</text><text start="1857.07" dur="5.849">basic questions are they even supposed</text><text start="1860.169" dur="6.36">to represent the same information</text><text start="1862.919" dur="6.34">sometimes numbers may be called the same</text><text start="1866.529" dur="3.011">thing but they&amp;#39;re actually not supposed</text><text start="1869.259" dur="2.891">to</text><text start="1869.54" dur="4.92">represent the same thing at all so an</text><text start="1872.15" dur="6.15">example would be that you know people</text><text start="1874.46" dur="5.7">may be just saying sign ups but maybe</text><text start="1878.3" dur="3.93">the sign ups that are stored on sales</text><text start="1880.16" dur="4.08">force on the Salesforce platform are</text><text start="1882.23" dur="3.86">referring to sign ups that need a</text><text start="1884.24" dur="3.72">customer success person to reach out</text><text start="1886.09" dur="3.37">whereas the sign ups that would be</text><text start="1887.96" dur="4.86">stored in your internal table would be</text><text start="1889.46" dur="5.04">all sign ups ever so you know you&amp;#39;re</text><text start="1892.82" dur="4.41">both calling it sign ups but is it</text><text start="1894.5" dur="6.18">actually all sign ups and the same</text><text start="1897.23" dur="5.94">amount the other thing to think about is</text><text start="1900.68" dur="4.77">I think this is actually super super</text><text start="1903.17" dur="5.22">common but you know are they from the</text><text start="1905.45" dur="5.01">same time frame and is your refresh data</text><text start="1908.39" dur="3.84">refresh cadence for the two places that</text><text start="1910.46" dur="4.68">you&amp;#39;re looking for information similar</text><text start="1912.23" dur="4.26">and that is I mean hands down</text><text start="1915.14" dur="4.77">one of the most common things that</text><text start="1916.49" dur="5.52">happens that like one report could be</text><text start="1919.91" dur="4.14">set to begin at the first of the month</text><text start="1922.01" dur="5.46">the other report is set for the first</text><text start="1924.05" dur="5.73">Monday of the month or like you know</text><text start="1927.47" dur="3.69">they&amp;#39;re set to different time zones just</text><text start="1929.78" dur="4.47">just things like that like they&amp;#39;re all</text><text start="1931.16" dur="4.68">time frame related things and those</text><text start="1934.25" dur="3.57">things you know again get it out of the</text><text start="1935.84" dur="4.52">way quick because that is that is</text><text start="1937.82" dur="5.73">usually a very common reason for</text><text start="1940.36" dur="5.23">misalignment to occur and the last thing</text><text start="1943.55" dur="3.15">here are sanity checklist wise is just</text><text start="1945.59" dur="4.2">human error</text><text start="1946.7" dur="5.16">you know there&amp;#39;s I mean I think all of</text><text start="1949.79" dur="4.29">us no matter how foolproof we make</text><text start="1951.86" dur="5.22">something there&amp;#39;s always gonna be some</text><text start="1954.08" dur="4.41">unintended use there could be some typos</text><text start="1957.08" dur="3.35">there could be some extra filters</text><text start="1958.49" dur="5.43">there&amp;#39;s just like basic things that are</text><text start="1960.43" dur="7.66">unintended how you intention for them to</text><text start="1963.92" dur="5.97">be used and then the last sort of</text><text start="1968.09" dur="4.77">checklist before we get into the coding</text><text start="1969.89" dur="4.92">is you know just understand understand</text><text start="1972.86" dur="5.13">the data set and understand what the</text><text start="1974.81" dur="5.43">problem is before you fully begin so</text><text start="1977.99" dur="4.68">here again the basic questions to ask</text><text start="1980.24" dur="4.02">you know what rules where each of the</text><text start="1982.67" dur="5.16">data sets built way like is it just</text><text start="1984.26" dur="5.25">purely raw data and presented as is or</text><text start="1987.83" dur="3.45">were there some transformations applied</text><text start="1989.51" dur="4.29">were there some business rules applied</text><text start="1991.28" dur="6.15">on top of it a lot of this information</text><text start="1993.8" dur="6.869">is unfortunately tribal knowledge and</text><text start="1997.43" dur="5.429">you again as a good data scientist</text><text start="2000.669" dur="4.021">and as a good citizen you have to you</text><text start="2002.859" dur="4.38">have to actually start documenting some</text><text start="2004.69" dur="5.609">of these things so that other detectives</text><text start="2007.239" dur="5.581">have an easier time and it&amp;#39;s um it&amp;#39;s</text><text start="2010.299" dur="5.1">totally worth the time the other common</text><text start="2012.82" dur="5.189">thing is the drain off the data set so</text><text start="2015.399" dur="4.86">you could very often have something</text><text start="2018.009" dur="4.77">where again they looked like they have</text><text start="2020.259" dur="4.8">the same number of columns but maybe</text><text start="2022.779" dur="4.59">they&amp;#39;re both aggregated at a completely</text><text start="2025.059" dur="5.041">different Lane and that could also</text><text start="2027.369" dur="5.37">result in some unintended things that</text><text start="2030.1" dur="5.309">you can&amp;#39;t see and finally is there a</text><text start="2032.739" dur="4.41">pipeline issue again that&amp;#39;s also very</text><text start="2035.409" dur="3.541">common that like you know the pipeline</text><text start="2037.149" dur="3.78">just breaks for a couple of hours or</text><text start="2038.95" dur="3.809">something like that and you&amp;#39;re missing</text><text start="2040.929" dur="6.96">data from a specific like chunk of time</text><text start="2042.759" dur="11.04">or or something weird is going on so now</text><text start="2047.889" dur="10.02">let&amp;#39;s sorry I just have some more okay</text><text start="2053.799" dur="7.681">so now let&amp;#39;s actually let&amp;#39;s actually get</text><text start="2057.909" dur="5.94">into some code so here&amp;#39;s what a dataset</text><text start="2061.48" dur="4.02">looks like it has an ID column and</text><text start="2063.849" dur="3.091">obviously there might be other columns</text><text start="2065.5" dur="3.69">as well but these are the relevant ones</text><text start="2066.94" dur="4.56">we look at there&amp;#39;s an odd order date</text><text start="2069.19" dur="4.59">there&amp;#39;s a region and there&amp;#39;s a sales</text><text start="2071.5" dur="6.659">amount and that&amp;#39;s sort of the basic</text><text start="2073.78" dur="6.51">thing that we&amp;#39;re dealing with so the</text><text start="2078.159" dur="3.93">most obvious check to start with when</text><text start="2080.29" dur="4.23">you&amp;#39;re comparing two different data sets</text><text start="2082.089" dur="4.59">to see what&amp;#39;s going on with them you</text><text start="2084.52" dur="4.289">know are they the same or not</text><text start="2086.679" dur="5.43">after answering all those sanity checks</text><text start="2088.809" dur="5.881">that we just did the first thing is do</text><text start="2092.109" dur="4.2">they have the same number of rows that</text><text start="2094.69" dur="4.02">can usually tell you a lot of what&amp;#39;s</text><text start="2096.309" dur="5.52">going on and so you know the simple</text><text start="2098.71" dur="5.19">thing there is just select count from</text><text start="2101.829" dur="3.811">from both of them compare that number of</text><text start="2103.9" dur="3.24">course you might decide to add like a</text><text start="2105.64" dur="4.169">where clause if you&amp;#39;re looking for a</text><text start="2107.14" dur="4.02">specific month or a specific region or</text><text start="2109.809" dur="3.451">whatever the difference is showing up</text><text start="2111.16" dur="6.51">but this is your absolute bare minimum</text><text start="2113.26" dur="5.91">starting point after that if they if</text><text start="2117.67" dur="3.87">they don&amp;#39;t actually have the same number</text><text start="2119.17" dur="4.61">of rows first thing is let&amp;#39;s look for</text><text start="2121.54" dur="5.46">missing information so in this example</text><text start="2123.78" dur="5.92">the ID was a unique column so we&amp;#39;re</text><text start="2127" dur="6.29">basically gonna look for we&amp;#39;re gonna</text><text start="2129.7" dur="5.68">find the missing ids and we&amp;#39;re gonna say</text><text start="2133.29" dur="3.89">you know which eye</text><text start="2135.38" dur="4.65">we&amp;#39;re going to do a full full join of</text><text start="2137.18" dur="4.95">the two tables and if the ID is null in</text><text start="2140.03" dur="4.95">one of the tables that&amp;#39;s the table that</text><text start="2142.13" dur="4.62">it&amp;#39;s missing from so this you know the</text><text start="2144.98" dur="3.99">second query should essentially give you</text><text start="2146.75" dur="4.73">a list of all the missing IDs and which</text><text start="2148.97" dur="5.64">ID which table they&amp;#39;re missing from and</text><text start="2151.48" dur="4.78">once you have that information we will</text><text start="2154.61" dur="3.09">discuss few different ways you can go</text><text start="2156.26" dur="6.45">about it but that should give you some</text><text start="2157.7" dur="7.74">information the next step you know I</text><text start="2162.71" dur="6">think even if you did find some missing</text><text start="2165.44" dur="5.13">information I think it&amp;#39;s still as long</text><text start="2168.71" dur="4.23">as like I think it&amp;#39;s still useful to</text><text start="2170.57" dur="4.53">look for duplicates anyways because</text><text start="2172.94" dur="4.83">again pipelines do weird things and</text><text start="2175.1" dur="6.54">funky stuff can happen so here again</text><text start="2177.77" dur="8.19">you&amp;#39;re simply you know getting all the</text><text start="2181.64" dur="6.45">all the I all the IDS you know grouping</text><text start="2185.96" dur="4.8">the IDs to get a count and you&amp;#39;re</text><text start="2188.09" dur="4.98">basically looking for any ID that has a</text><text start="2190.76" dur="5.42">count greater than one from each table</text><text start="2193.07" dur="5.7">and you&amp;#39;re unioning those two those two</text><text start="2196.18" dur="3.97">sub-queries and getting your final</text><text start="2198.77" dur="4.62">result that gives you the final answer</text><text start="2200.15" dur="5.61">so this way again you&amp;#39;ll have one one</text><text start="2203.39" dur="4.23">result that will give you all the</text><text start="2205.76" dur="4.65">duplicate IDs that are that are missing</text><text start="2207.62" dur="5.31">so that are that are duplicates and and</text><text start="2210.41" dur="5.01">which table there are duplicate in so</text><text start="2212.93" dur="3.69">these these queries that we have so far</text><text start="2215.42" dur="3">like of course there could be a lot of</text><text start="2216.62" dur="4.02">like extra clauses that you can build</text><text start="2218.42" dur="4.14">into it but just kind of sharing it as</text><text start="2220.64" dur="3.75">examples of life starting points of how</text><text start="2222.56" dur="6.93">to start even thinking about some of</text><text start="2224.39" dur="8.07">these issues next and you know sort of</text><text start="2229.49" dur="5.76">the last sequel level check that I</text><text start="2232.46" dur="6.06">talked about is just doing a check at</text><text start="2235.25" dur="5.22">the dimension level so here is where it</text><text start="2238.52" dur="3.45">gets interesting and where your</text><text start="2240.47" dur="3.42">familiarity with the data can really</text><text start="2241.97" dur="3.48">help but again in this example you&amp;#39;re</text><text start="2243.89" dur="4.92">new to the companies you have no idea</text><text start="2245.45" dur="5.04">what&amp;#39;s going on once you&amp;#39;ve sort of</text><text start="2248.81" dur="5.25">eliminated some of the basic things you</text><text start="2250.49" dur="5.76">want to start breaking things down by</text><text start="2254.06" dur="6.89">you know one dimension at a time and</text><text start="2256.25" dur="7.77">seeing you know is there a case where</text><text start="2260.95" dur="6.61">things are consistently off across</text><text start="2264.02" dur="4.41">dimensions or it&amp;#39;s only one dimension</text><text start="2267.56" dur="3.39">where there&amp;#39;s something</text><text start="2268.43" dur="5.27">gone wrong so like for example in this</text><text start="2270.95" dur="9.18">query I am looking essentially for</text><text start="2273.7" dur="9.58">regions there the region the sales the</text><text start="2280.13" dur="4.89">sum of the sales for a region in table</text><text start="2283.28" dur="5.22">one is different from the sum of the</text><text start="2285.02" dur="6.87">sales in region two and in the same in</text><text start="2288.5" dur="5.52">table 2 for the same region and this so</text><text start="2291.89" dur="4.44">that&amp;#39;s why I&amp;#39;m only doing like I&amp;#39;m only</text><text start="2294.02" dur="5.34">looking for I&amp;#39;m only gonna it&amp;#39;s only</text><text start="2296.33" dur="4.92">gonna result in the rows that have that</text><text start="2299.36" dur="4.5">have a difference and that is</text><text start="2301.25" dur="4.83">immediately gonna tell me like if I see</text><text start="2303.86" dur="4.59">all the regions then the problem is</text><text start="2306.08" dur="4.32">either on a different dimension or</text><text start="2308.45" dur="4.98">there&amp;#39;s something else going on but if</text><text start="2310.4" dur="5.25">this data shows me that oh only region</text><text start="2313.43" dur="3.81">that has a problem is say the East</text><text start="2315.65" dur="3.66">region or something then that</text><text start="2317.24" dur="4.17">immediately tells me that the rest of my</text><text start="2319.31" dur="3.84">pipeline is probably fine or my rest of</text><text start="2321.41" dur="4.29">my feature definition is fine but at</text><text start="2323.15" dur="5.52">least I know to narrow down that I have</text><text start="2325.7" dur="4.65">to go do something about the East region</text><text start="2328.67" dur="3.84">because that&amp;#39;s where my problem is</text><text start="2330.35" dur="4.35">showing up and like you like I said like</text><text start="2332.51" dur="4.2">if if the if all the regions are equally</text><text start="2334.7" dur="3.78">off then you break it down by a</text><text start="2336.71" dur="4.47">different dimension maybe it&amp;#39;s the</text><text start="2338.48" dur="5.28">product or something else but the point</text><text start="2341.18" dur="6.09">is to keep doing those cuts until you</text><text start="2343.76" dur="8.34">find something where you have a step to</text><text start="2347.27" dur="7.29">dig further so this is you know these</text><text start="2352.1" dur="4.74">are obviously I mean these examples have</text><text start="2354.56" dur="4.32">this example has been simplified to sort</text><text start="2356.84" dur="5.31">of give you a give you a taste of what</text><text start="2358.88" dur="6.36">what what this looks like but you know I</text><text start="2362.15" dur="4.98">I expect that people will as they become</text><text start="2365.24" dur="4.17">more familiar with datasets they will</text><text start="2367.13" dur="4.59">build their own scripts and write their</text><text start="2369.41" dur="6.39">own queries to resolve common problems</text><text start="2371.72" dur="6.27">and I think you know you should ideally</text><text start="2375.8" dur="4.35">make these things modular so that you</text><text start="2377.99" dur="5.73">can convert those code snippets easily</text><text start="2380.15" dur="5.7">and share them with the you know share</text><text start="2383.72" dur="3.81">them save them converted into reusable</text><text start="2385.85" dur="4.68">modules so that you can like change</text><text start="2387.53" dur="5.22">change things and and kind of go around</text><text start="2390.53" dur="4.08">it and you can also convert some of</text><text start="2392.75" dur="4.47">these things to visualizations to help</text><text start="2394.61" dur="5.46">you spot errors faster so for example</text><text start="2397.22" dur="4.29">like in my you know in in in one of the</text><text start="2400.07" dur="1.92">places I used to work at like I had</text><text start="2401.51" dur="2.79">these</text><text start="2401.99" dur="5.09">like just kind of ready to go cuz Elvis</text><text start="2404.3" dur="5.19">knew where the pipeline would break and</text><text start="2407.08" dur="4.06">it was a different team that had to fix</text><text start="2409.49" dur="3.3">the pipeline so I just had to provide</text><text start="2411.14" dur="4.35">them the proof that the pipeline was</text><text start="2412.79" dur="5.04">broken so I had these scripts is ready</text><text start="2415.49" dur="3.9">to go and when it wasn&amp;#39;t a pipeline</text><text start="2417.83" dur="3.51">issue when it was a feature definition</text><text start="2419.39" dur="3.06">issue I would have like I would go</text><text start="2421.34" dur="2.46">through this because that was the most</text><text start="2422.45" dur="3.06">common thing and then I would have</text><text start="2423.8" dur="4.41">something else to go through those I</text><text start="2425.51" dur="4.35">knew that okay for feature stuff I write</text><text start="2428.21" dur="4.37">different scripts or I have different</text><text start="2429.86" dur="5.34">filters or some or something like that</text><text start="2432.58" dur="4.51">and yeah you can you can kind of like</text><text start="2435.2" dur="7.02">build on these as you as you get more</text><text start="2437.09" dur="7.529">comfortable with the data so to wrap it</text><text start="2442.22" dur="6.84">up I think one of the things to keep in</text><text start="2444.619" dur="6.061">mind is that you know as as we saw</text><text start="2449.06" dur="4.62">through a bit of the examples like</text><text start="2450.68" dur="7.53">prevention is a lot better than cure and</text><text start="2453.68" dur="7.32">you know a lot of the sanity checks that</text><text start="2458.21" dur="4.409">we do before we before we do anything</text><text start="2461" dur="3.21">before we look into stuff like a lot of</text><text start="2462.619" dur="3.661">it comes into things that are easy to</text><text start="2464.21" dur="4.29">prevent if you do it in the beginning so</text><text start="2466.28" dur="5.76">if you&amp;#39;re as a company committed to</text><text start="2468.5" dur="5.73">reconciling on terminologies documenting</text><text start="2472.04" dur="4.41">stuff making sure everybody is data</text><text start="2474.23" dur="4.8">literate it makes your life and</text><text start="2476.45" dur="4.65">everybody&amp;#39;s life a whole lot easier and</text><text start="2479.03" dur="4.29">I also think like automating stuff is</text><text start="2481.1" dur="4.59">extremely important like you should not</text><text start="2483.32" dur="5.37">have to do anything manually if you&amp;#39;re</text><text start="2485.69" dur="5.669">if you&amp;#39;re doing it more than once then</text><text start="2488.69" dur="4.08">by all means be absolutely lazy and just</text><text start="2491.359" dur="3.601">do it once then never do it again</text><text start="2492.77" dur="4.89">and automate it because I think I think</text><text start="2494.96" dur="5.72">that those that actually allows you to</text><text start="2497.66" dur="5.19">be be more efficient in what&amp;#39;s going on</text><text start="2500.68" dur="5.22">the other thing is just simplify your</text><text start="2502.85" dur="6.93">curated data sets so anything that has</text><text start="2505.9" dur="6.219">way too much information that you don&amp;#39;t</text><text start="2509.78" dur="5.1">use is going to be very hard to debug</text><text start="2512.119" dur="4.411">when a problem occurs because you just</text><text start="2514.88" dur="3.93">have so many different things to look at</text><text start="2516.53" dur="4.92">so keep it extremely simple keep it</text><text start="2518.81" dur="5.94">aggregated to a level that you expect it</text><text start="2521.45" dur="5.79">to work at and that way also specially</text><text start="2524.75" dur="4.2">like like at my company we use snowflake</text><text start="2527.24" dur="3.75">which is which is super fast but like</text><text start="2528.95" dur="4.83">you know some of the old data warehouses</text><text start="2530.99" dur="3.73">it takes a while to run some queries so</text><text start="2533.78" dur="3.55">it makes sense</text><text start="2534.72" dur="4.77">if you have something that&amp;#39;s you know</text><text start="2537.33" dur="5.34">simple and aggregated so that you only</text><text start="2539.49" dur="5.82">go up one level if you if you pinpointed</text><text start="2542.67" dur="5.07">the problem to like one one section and</text><text start="2545.31" dur="5.25">yeah I think again like it&amp;#39;s very</text><text start="2547.74" dur="5.52">important to have an actual governance</text><text start="2550.56" dur="4.32">standard and you know some sort of a</text><text start="2553.26" dur="3.51">philosophy about who owns ooh art who</text><text start="2554.88" dur="4.08">owns which part getting broken who&amp;#39;s in</text><text start="2556.77" dur="5.099">charge of reporting things things like</text><text start="2558.96" dur="4.889">that I think are extremely are extremely</text><text start="2561.869" dur="4.201">required and you should also have an</text><text start="2563.849" dur="5.221">audit process so at some point you</text><text start="2566.07" dur="6.81">should do some kind of a quality or you</text><text start="2569.07" dur="5.85">know a data cleanup hackathon that that</text><text start="2572.88" dur="5.31">is that is able to sort of address some</text><text start="2574.92" dur="7.5">of these some of these issues so yeah I</text><text start="2578.19" dur="5.61">guess you know overall like I think sort</text><text start="2582.42" dur="3.36">of wrapping up the philosophy and the</text><text start="2583.8" dur="3.96">methodology like you know keep keep</text><text start="2585.78" dur="4.41">breaking down the problem into smaller</text><text start="2587.76" dur="4.38">parts until you are able to fully</text><text start="2590.19" dur="6.12">isolate where differences are occurring</text><text start="2592.14" dur="6.27">and bad bad data is creeping up and you</text><text start="2596.31" dur="4.14">know the the the truth is out there</text><text start="2598.41" dur="4.23">somewhere like you just you just have to</text><text start="2600.45" dur="5.61">sort of like keep finding a way to get</text><text start="2602.64" dur="5.07">to it and yeah with that I I just wanted</text><text start="2606.06" dur="4.62">to leave you all with some additional</text><text start="2607.71" dur="4.77">research and reference material I think</text><text start="2610.68" dur="3.84">there are some great thoughts that</text><text start="2612.48" dur="4.29">people shared about like bad data and</text><text start="2614.52" dur="4.77">also how to think like Sherlock Holmes</text><text start="2616.77" dur="5.43">which you can apply for other things as</text><text start="2619.29" dur="4.89">well and I also linked my own talk about</text><text start="2622.2" dur="5.639">thoughtful analytics in case anybody is</text><text start="2624.18" dur="6.27">interested it is also on my website and</text><text start="2627.839" dur="5.161">yeah that&amp;#39;s that&amp;#39;s that&amp;#39;s that&amp;#39;s it for</text><text start="2630.45" dur="5.22">today thanks so much for attending a</text><text start="2633" dur="5.099">special thank you for asthma and data</text><text start="2635.67" dur="4.32">umbrella for hosting me this is this is</text><text start="2638.099" dur="4.861">extremely fun I haven&amp;#39;t actually done a</text><text start="2639.99" dur="5.55">technical webinar ever so this is</text><text start="2642.96" dur="5.19">solving in-person services 10 fun for me</text><text start="2645.54" dur="5.309">I hope you found the content useful I</text><text start="2648.15" dur="4.92">will be taking some questions now but</text><text start="2650.849" dur="4.621">also keep in mind that data umbrella is</text><text start="2653.07" dur="4.08">going to publish a recording of this on</text><text start="2655.47" dur="3.96">their website as well as on their</text><text start="2657.15" dur="4.79">YouTube channel and I&amp;#39;ll be doing the</text><text start="2659.43" dur="4.83">same as well in about a month&amp;#39;s time so</text><text start="2661.94" dur="5.53">you know feel free to stay in touch with</text><text start="2664.26" dur="3.809">me on Twitter and also if you have any</text><text start="2667.47" dur="4.259">questions</text><text start="2668.069" dur="9.331">I can answer them too right now yeah you</text><text start="2671.729" dur="7.47">can hear me right yeah great yeah if</text><text start="2677.4" dur="5.309">anybody has any questions if you just</text><text start="2679.199" dur="6.33">want to post it on chat um we have about</text><text start="2682.709" dur="10.29">ten minutes left in the hour so we could</text><text start="2685.529" dur="11.67">answer any questions any questions or</text><text start="2692.999" dur="9.72">any observations anything else that</text><text start="2697.199" dur="9.03">you&amp;#39;ve noticed that helps you do we have</text><text start="2702.719" dur="5.221">Rene Phillips here who is like she&amp;#39;s</text><text start="2706.229" dur="4.38">like very very involved in Postgres</text><text start="2707.94" dur="9.72">women SQL and in the conference</text><text start="2710.609" dur="8.791">organizing the conference as well and do</text><text start="2717.66" dur="4.889">you show me do you want to put in the</text><text start="2719.4" dur="5.699">chat the link to the careers page for</text><text start="2722.549" dur="13.98">Komodo health yeah let me let me quickly</text><text start="2725.099" dur="14.61">grab that thank you</text><text start="2736.529" dur="6.78">what&amp;#39;s the hardest data quality problem</text><text start="2739.709" dur="7.14">I have faced um that&amp;#39;s to be very very</text><text start="2743.309" dur="4.17">frank it&amp;#39;s so I go with the hardest one</text><text start="2746.849" dur="3.39">first</text><text start="2747.479" dur="5.58">honestly it&amp;#39;s convincing people that</text><text start="2750.239" dur="5.191">it&amp;#39;s important which which should not be</text><text start="2753.059" dur="4.321">a thing but you know I think I think</text><text start="2755.43" dur="4.679">some organizations have very good data</text><text start="2757.38" dur="4.56">hygiene and they know sort of all the</text><text start="2760.109" dur="3.781">downstream issues that it can cause if</text><text start="2761.94" dur="4.71">you don&amp;#39;t notice these things up front</text><text start="2763.89" dur="5.669">but I did work in an organization once</text><text start="2766.65" dur="4.26">where it was just it was you know there</text><text start="2769.559" dur="4.321">was just absolutely like there was a</text><text start="2770.91" dur="4.859">wild wild west of like everybody just</text><text start="2773.88" dur="4.829">kind of do whatever and you&amp;#39;ll figure it</text><text start="2775.769" dur="5.01">out later and it caught it cause it was</text><text start="2778.709" dur="4.25">so costly because it took so many people</text><text start="2780.779" dur="4.5">so much time to try to like you know</text><text start="2782.959" dur="6.82">reset some of the things that were just</text><text start="2785.279" dur="8.881">very very bad and yeah that was that was</text><text start="2789.779" dur="9.601">pretty hard the most fun one I would say</text><text start="2794.16" dur="7.82">is yeah I you know I I just I like I</text><text start="2799.38" dur="7.64">like investigating stuff like</text><text start="2801.98" dur="7.53">i i like having an analysis that I trust</text><text start="2807.02" dur="5.31">so if there&amp;#39;s something that comes up</text><text start="2809.51" dur="6.39">which you know which I&amp;#39;m confused like</text><text start="2812.33" dur="7.08">oh my why&amp;#39;d you know why does this seem</text><text start="2815.9" dur="5.58">odd sometimes that entire investigation</text><text start="2819.41" dur="4.17">is because I think there&amp;#39;s bad data and</text><text start="2821.48" dur="4.94">maybe at the end of it I prove that it&amp;#39;s</text><text start="2823.58" dur="5.49">not like this is legitimately what our</text><text start="2826.42" dur="4.33">what our data is telling us that&amp;#39;s I</text><text start="2829.07" dur="3.96">think that&amp;#39;s still a good outcome for me</text><text start="2830.75" dur="4.14">because I think that whole process makes</text><text start="2833.03" dur="4.44">me understand the data a lot better</text><text start="2834.89" dur="4.95">makes me trust different parts of it a</text><text start="2837.47" dur="3.81">lot better so I I do find it fun to have</text><text start="2839.84" dur="4.4">these challenges every once in a while</text><text start="2841.28" dur="9.81">because I think it allows me to engage</text><text start="2844.24" dur="8.71">with things more Ruchika us how do you</text><text start="2851.09" dur="4.83">take care of bias in the data when</text><text start="2852.95" dur="4.05">historically there has been a lot so</text><text start="2855.92" dur="3.24">that&amp;#39;s an interesting that&amp;#39;s an</text><text start="2857" dur="4.35">interesting question I guess my first</text><text start="2859.16" dur="4.68">question to that would be like how do</text><text start="2861.35" dur="4.08">you know there is there is bias or is it</text><text start="2863.84" dur="11.82">just that you&amp;#39;re trying to make sure</text><text start="2865.43" dur="12.57">that there is there is no bias so Arouca</text><text start="2875.66" dur="4.26">I don&amp;#39;t know if you had a specific sort</text><text start="2878" dur="4.23">of thing in mind but I guess I&amp;#39;ll just</text><text start="2879.92" dur="5.07">give you I guess I&amp;#39;ll just give you a</text><text start="2882.23" dur="6.6">general making sure that there&amp;#39;s no bias</text><text start="2884.99" dur="7.29">okay yeah I guess I guess for me I am</text><text start="2888.83" dur="6.92">always trying to look at the use case I</text><text start="2892.28" dur="6.24">think you know whatever I&amp;#39;m trying to do</text><text start="2895.75" dur="7.6">whatever I&amp;#39;m trying to get to as an</text><text start="2898.52" dur="6.51">answer like I think honestly for me it</text><text start="2903.35" dur="4.35">really comes down to talking to a lot of</text><text start="2905.03" dur="4.86">people and kind of almost poking holes</text><text start="2907.7" dur="6.06">at a problem like what are the what are</text><text start="2909.89" dur="5.82">the ways this could go wrong well you</text><text start="2913.76" dur="4.74">know we&amp;#39;re we&amp;#39;re doing something</text><text start="2915.71" dur="6.149">unintended I actually in one of the</text><text start="2918.5" dur="5.04">companies I used to actually sit go and</text><text start="2921.859" dur="3.721">sit with the customer support teams</text><text start="2923.54" dur="3.81">occasionally and like get them to tell</text><text start="2925.58" dur="3.06">me like you know just show me examples</text><text start="2927.35" dur="4.95">of what people are complaining about</text><text start="2928.64" dur="5.19">about our software and you know that</text><text start="2932.3" dur="3.51">actually started an initiative where we</text><text start="2933.83" dur="3.6">would we would flag things which</text><text start="2935.81" dur="3.18">seem like people just didn&amp;#39;t trust</text><text start="2937.43" dur="3.57">something that was happening like they</text><text start="2938.99" dur="4.59">didn&amp;#39;t they didn&amp;#39;t think it made sense</text><text start="2941" dur="5.61">and some of those things were I mean</text><text start="2943.58" dur="4.44">there was like it was just there was no</text><text start="2946.61" dur="3.15">reason for them to not trust it but</text><text start="2948.02" dur="3.3">other things like it made sense and we</text><text start="2949.76" dur="3.72">did actually do some investigations</text><text start="2951.32" dur="3.66">where they&amp;#39;re like yeah the reason why</text><text start="2953.48" dur="3.6">this person said this looks suspicious</text><text start="2954.98" dur="3.54">makes sense because there is there is</text><text start="2957.08" dur="4.71">something odd happening there and that</text><text start="2958.52" dur="5.4">doesn&amp;#39;t make sense</text><text start="2961.79" dur="4.17">milena what tools you use to clean up</text><text start="2963.92" dur="5.37">the data so I think that for me depends</text><text start="2965.96" dur="6.24">on what what I&amp;#39;m actually using so I</text><text start="2969.29" dur="6.51">typically access most of my data in a</text><text start="2972.2" dur="7.38">sequel warehouse and I end up doing a</text><text start="2975.8" dur="6.93">lot of it there if I have exported it</text><text start="2979.58" dur="5.82">out then I usually use art but again</text><text start="2982.73" dur="4.47">that&amp;#39;s just my preference my my entire</text><text start="2985.4" dur="3.66">team is very much on the Pythian</text><text start="2987.2" dur="7.14">bandwagon and that&amp;#39;s that&amp;#39;s what they</text><text start="2989.06" dur="7.26">use yeah what additional functionality</text><text start="2994.34" dur="4.68">and unique capabilities does snowflake</text><text start="2996.32" dur="4.89">provide oh I have to tell you I&amp;#39;m very</text><text start="2999.02" dur="4.68">biased towards snowflake I am a huge</text><text start="3001.21" dur="4.17">huge snowflake fan girl when I was</text><text start="3003.7" dur="3.21">joining Komodo health actually one of</text><text start="3005.38" dur="3.42">the first question I ask them is do you</text><text start="3006.91" dur="4.05">have snowflake and they said yes and so</text><text start="3008.8" dur="3.48">I joined because my previous company did</text><text start="3010.96" dur="3.93">not have snowflake and I was very</text><text start="3012.28" dur="4.05">annoyed by that for the two and a half</text><text start="3014.89" dur="4.02">years that I work there</text><text start="3016.33" dur="6.18">snowflake is just really fast it&amp;#39;s it&amp;#39;s</text><text start="3018.91" dur="5.91">it&amp;#39;s such a it&amp;#39;s I mean yeah I I&amp;#39;m like</text><text start="3022.51" dur="5.28">I said I am amazingly I like to spend</text><text start="3024.82" dur="5.25">less time doing stuff so I was on</text><text start="3027.79" dur="3.69">hurting for awhile and those things used</text><text start="3030.07" dur="3.63">to take me like 20 minutes to run a</text><text start="3031.48" dur="4.61">query and then in snowflake that same</text><text start="3033.7" dur="7.56">query would take a less than a minute</text><text start="3036.09" dur="9.85">say I I I&amp;#39;m not paid by them but I do</text><text start="3041.26" dur="7.05">like their to me quite a bit I have a</text><text start="3045.94" dur="4.29">question for you I was thinking when</text><text start="3048.31" dur="2.73">you&amp;#39;re working with that many millions</text><text start="3050.23" dur="3.84">of Records</text><text start="3051.04" dur="5.96">do you often find those cases that are</text><text start="3054.07" dur="5.46">you know just a handful that are</text><text start="3057" dur="4.54">problematic and heavy it&amp;#39;s is it like</text><text start="3059.53" dur="3.12">finding a needle in a haystack or is it</text><text start="3061.54" dur="3">something that really just sort of</text><text start="3062.65" dur="5.82">breaks all your programs because it&amp;#39;s</text><text start="3064.54" dur="5.04">that exception yeah that&amp;#39;s a that&amp;#39;s a</text><text start="3068.47" dur="4.77">great question so</text><text start="3069.58" dur="5.58">you know some of the so some of the most</text><text start="3073.24" dur="3.33">like often that I did these</text><text start="3075.16" dur="3.93">investigations that actually at</text><text start="3076.57" dur="8.16">Salesforce where the platform that I</text><text start="3079.09" dur="8.13">worked on had 340 million users so it</text><text start="3084.73" dur="4.53">was obviously yeah it was it was just a</text><text start="3087.22" dur="4.71"> ton of junk data that was generated</text><text start="3089.26" dur="4.83">for Ford the stuff that we were using</text><text start="3091.93" dur="3.78">and that was the time I did not have</text><text start="3094.09" dur="4.74">snowflake so my queries would actually</text><text start="3095.71" dur="6.66">take longer and then like that&amp;#39;s the</text><text start="3098.83" dur="5.04">thing that I got to like I think like we</text><text start="3102.37" dur="3.39">had a little bit of an understanding of</text><text start="3103.87" dur="5.79">like I think when I was a kissed able to</text><text start="3105.76" dur="6.18">explain like here&amp;#39;s why this data is</text><text start="3109.66" dur="5.01">always gonna be slightly shifted from</text><text start="3111.94" dur="4.65">this other data then people have less of</text><text start="3114.67" dur="5.07">a problem like if they if I if I&amp;#39;ve done</text><text start="3116.59" dur="6.45">that true once where it&amp;#39;s like you know</text><text start="3119.74" dur="5.49">we expect there to be a 1% difference</text><text start="3123.04" dur="4.92">when you&amp;#39;re pulling it from this source</text><text start="3125.23" dur="3.99">versus this source because you know</text><text start="3127.96" dur="2.58">they&amp;#39;re they&amp;#39;re out of sync they&amp;#39;re</text><text start="3129.22" dur="2.91">never gonna be insane there&amp;#39;s always</text><text start="3130.54" dur="3.15">gonna be a little bit of lag here or</text><text start="3132.13" dur="4.74">something like that like then people</text><text start="3133.69" dur="5.22">have then if people understand it</text><text start="3136.87" dur="3.72">they&amp;#39;re okay with it but if that shift</text><text start="3138.91" dur="4.65">ever like really changes like suddenly</text><text start="3140.59" dur="4.62">even from 1% it goes to 1.5 like if it&amp;#39;s</text><text start="3143.56" dur="5.45">crossed a threshold that we have</text><text start="3145.21" dur="6.24">established as unknown then it warrants</text><text start="3149.01" dur="3.58">investigation like what&amp;#39;s what&amp;#39;s going</text><text start="3151.45" dur="2.85">on like is this something that&amp;#39;s</text><text start="3152.59" dur="4.19">breaking or is this really my data</text><text start="3154.3" dur="5.55">changing and I think in that like again</text><text start="3156.78" dur="6.4">the more time I spent with that data the</text><text start="3159.85" dur="4.71">more sort of checks I built in one thing</text><text start="3163.18" dur="4.08">I forgot to mention but like some of</text><text start="3164.56" dur="5.49">these queries that I had pulled put out</text><text start="3167.26" dur="5.22">I actually you know got some of the data</text><text start="3170.05" dur="4.17">engineers to convert them into alerts so</text><text start="3172.48" dur="4.59">that if some of those checks didn&amp;#39;t pass</text><text start="3174.22" dur="5.58">it would actually like things that I</text><text start="3177.07" dur="4.68">knew were to be true like I would have</text><text start="3179.8" dur="3.96">them coded into the things so that</text><text start="3181.75" dur="4.02">before that data was even published it</text><text start="3183.76" dur="3.81">would go through all of those checks and</text><text start="3185.77" dur="3.96">if something failed it would not publish</text><text start="3187.57" dur="3.9">that data set so that then I could go</text><text start="3189.73" dur="3.6">and look at it and be like does this</text><text start="3191.47" dur="4.14">look fine or does this not does this</text><text start="3193.33" dur="3.66">require extra investigation and I think</text><text start="3195.61" dur="3.27">that was really helpful because then</text><text start="3196.99" dur="4.14">you&amp;#39;re not on a totally by goose chase</text><text start="3198.88" dur="5.78">you&amp;#39;re actually you know you&amp;#39;re saying</text><text start="3201.13" dur="5.91">like sure here&amp;#39;s what went wrong in here</text><text start="3204.66" dur="5.58">that&amp;#39;s what in pharma we used to call</text><text start="3207.04" dur="10.17">those edit chicks yeah the same thing</text><text start="3210.24" dur="8.92">yeah yeah cuz we have another couple of</text><text start="3217.21" dur="4.19">minutes does anybody else have any</text><text start="3219.16" dur="2.24">questions</text><text start="3226.95" dur="8.44">awesome so thank you so much for joining</text><text start="3232.99" dur="3.75">us I&amp;#39;m from San Fran&amp;#39;s an Francisco</text><text start="3235.39" dur="4.86">right your that&amp;#39;s where you are I&amp;#39;m in</text><text start="3236.74" dur="6.48">New York and the recording will be</text><text start="3240.25" dur="5.369">available soon I&amp;#39;ll send a message the</text><text start="3243.22" dur="9.06">meetup group it&amp;#39;s on our data umbrella</text><text start="3245.619" dur="8.43">events page and Renee is asking if you</text><text start="3252.28" dur="6.45">would like to do a webinar for Postgres</text><text start="3254.049" dur="8.421">women New York City yes absolutely thank</text><text start="3258.73" dur="7.139">you all right um thank you everybody and</text><text start="3262.47" dur="5.829">watch our meetup page for upcoming</text><text start="3265.869" dur="5.421">events have a good night awesome thank</text><text start="3268.299" dur="2.991">you so much it&amp;#39;s</text></transcript>