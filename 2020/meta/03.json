{"presenter": "Ty Shaikh", "title": "Scraping Poshmark Data with Python", "year": "2020", "transcript_md": "03-ty-shaikh-webscraping.md", "meetup_url": "https://www.meetup.com/nyc-data-umbrella/events/270285046/", "yt_video_id": "0L1uM_18TTA", "slides_url": "N.A.", "repo_url": "https://github.com/ty-shaikh/scraping_poshmark_webinar", "notebook_url": "N.A.", "transcriber": "?", "extra_references": "- Binder:  https://mybinder.org/v2/gh/ty-shaikh/scraping_poshmark_webinar/master?filepath=1-scraping_poshmark_listings.ipynb \n", "video_href_w": "25%", "video_href": "http://www.youtube.com/watch?feature=player_embedded&v=0L1uM_18TTA", "video_href_src": "http://img.youtube.com/vi/0L1uM_18TTA/0.jpg", "video_href_alt": "Scraping Poshmark with Python", "formatted_transcript": "Hi everyone I am doing a recording of the scraping presentation the original recording from the webinar didn't come out well so this is just a re-recording. In\ntoday's presentation I'm going to talk about web scraping. We're going to look at the website Poshmark.com and we're going to use Python and some additional\npackages to gather the data. So agenda I'm gonna give a quick introduction about myself and the group. Then we're going to talk about web scraping and high level. Then we'll walk through a code example.\n\n### Start introduction (0:36 / 44:31)\nI'm going to share the code files so you can walk through it on your own as well and then during the webinar\nthere was obviously QA it's a little bit\nabout me I'm a product manager with\nGeneral Assembly I used to run\noperations at an online data science\nbootcamp and that's kind of where I\npicked up everything I know about Python\nand programming and data science and\nthen I'm a assistant organizer with data\numbrella so a little bit more about data\numbrella the mission of the group is to\nprovide a welcoming and educational\nspace for underrepresented groups or you\nare G's in the fields of data science\nand machine learning and we primarily do\nthis through meet of events now virtual\nwebinars and open source sprints with\nmost of our events it's open to people\nof all levels we we usually assume some\nfamiliarity with Python or data signs\nbut we're happy to have beginners to\nadvanced people attend and then we're\nalways looking for volunteers and\nspeakers so you can check out our\nhomepage at data umbrella org and reach\nout to us if you want to learn more\nso what is web scraping I've pasted the\nreally technical dictionary definition\nhere which is the programmatic\nextraction of unstructured data from\nwebsites to usable structured data if\nyou have a technical background you\nprobably understand what this means but\nfor most people this is just a bit out\nthere so let's take a look at a\npractical example on the Left we have a\nscreen shot of Amazon listings for TVs\nand on the right is what our output\nwould look like from scraping so if you\ntake a look at each row which has an\nitem you see that there's there's tons\nof usable information right we see the\nbrand Samsung the size of the TV the\ntype of TV resolution like 4k or 5k if\nit's a smart TV or not then you can see\nhow many reviews were written what was\nthe average rating the price the\ndiscount the original price the shipping\nhow many are in stock are there used\nused or other seller selling so we can\nsee that all on the website but that's\nnot in a usable form unless you're you\nknow just using your eyes you can you\ncan read that you can digest that but\nit's a we wanted to do extract the data\nfor like 10,000 TV listings right like I\ncould do this manually for five or ten\nor a hundred and would be that bad but\nif we wanted to repeat that process for\na thousand or 10,000 listings you'd want\nto use web scraping and with web\nscraping we can extract out the\nindividual values from this website and\nextract out the brand the TV size\nwhether it's a smart TV or not what the\nprice is whether there's price prime\nshipping or not and I'll do a little\nassign and kind of explain how web pages\nwork here as well web pages are built\nwith HTML and CSS so this is the output\nbut there are two components so HTML is\nreally\nthe layout and the content so for\nexample in HTML you'll see a block that\nsays Samsung and this text and then\nyou'll see a block that has the price a\nblock that has the image and then what\nCSS does is you add classes to different\nHTML blocks and for example in CSS you\ncan tell it to make this image 200 by\n200 pixels you can tell the web page to\nprint this out and smaller font and red\nso that's what CSS does right make this\nfont Orange make this fawn bigger and\nbold and so HTML gives it the layout so\nwe want text here we want the stars here\nwe want more text to the pricing here we\nwant the shipping text here we want the\nstock pricing and then CSS tells you how\nto style that so we want the shipping in\ngray and smaller and then we want this\nin red so that's that's how those work\nand and we'll take a look at that in the\ncode notebook I thought I'd just give\nyou a a brief summary of that so how is\nweb scraping used in real life these are\njust a couple use cases there's dozens\nmore so you can keep track of\ncompetitors monitor consumer sentiment\nso looking at reviews aggregate news and\nother data like on Amazon lead\ngeneration and CRM in Richmond so\nfinding out the background of people\nthat contact you gathering data for news\nstories like 538 and the New York Times\nThe Washington Post\nso what are we scraping today we're\ngoing to be looking at posh Montcalm so\nif you're not familiar with posh mark\nyou can think of it more as like a hip\neBay or Etsy it's basically a social\nplatform for clothing shoes and\naccessories so you can buy and sell used\nand new clothing items and it's become\nincredibly popular with the with the\nyounger audience the millennial and\nyounger generation but I think I think\nit's a cool platform I've actually used\nit a couple times to buy some items I\nlike fashion so I thought it was cool\nand there was the reason I was actually\ninterested in scraping Poshmark\nis that compared to other social\ncommerce platforms they don't have like\na saved search feature so say you're\nreally interested in the example here\nlike you really want Clark boots in a\ncertain style and a certain size there's\nactually no way I mean it's probably on\nthe roadmap I don't know why they\nhaven't built it but there's no way to\nlike save that search and get like a\ndaily digest or weekly digest at least\nin the last month when I saw it so on\neBay or Etsy or really any other social\ncommerce platform you usually can save\nyour search and get like a daily digest\nor a weekly digest like hey these were\nthe items posted in that and so I did\nthis scraping exercise in order to build\nlike a personal email reminder that\nwould send me updates like hey these\nthings were were posted under this\ncategory or and good.this like these\nparameters and I mean it's it's on the\nroad max map somewhere I mean dozens of\npeople have told them I've seen people\ncomplain about it online and like read\nanother like public review and forums so\nit's definitely there but that was kind\nof my interest in scraping so I would\nscrape a certain search and then send\nmyself an email reminder so to get\nstarted you can just access this link\ngoes to my github repo and and I've\nincluded this this binder blank it's a\ncloud-based program which allows you to\nrun Jupiter notebooks and I've seen some\nother people use it and essentially what\nit does is it builds a docker image\nunder the hood\ndon't take a probably 20 or 30 seconds\nto get running okay so I'm just gonna go\nline by line and walk through my logic\nand the decisions I made and then yeah\nand that's pretty much the presentation\nwill comprise of the rest of the\nnotebook\nto get started the first cell is really\njust a way to set some custom settings\nand ipython so I'm just expanding the\nwindow and making the text bigger\nwebpages one on one the websites are\nbuilt using HTML and CSS HTML is a type\nof markup language you can think of it\nsimilar to markdown it provides the\nlayout for our websites and then CSS\nprovides the styling so when you have\ndifferent font sizes colors of text and\nbackgrounds spacing between elements and\nyou can see here we have a screenshot of\nPoshmark but why don't we just take a\nlook at the actual website and this is\nPoshmark com you aren't familiar it's\nit's just a social commerce platform so\nthere are listings of diesel men's jeans\nhere and you can see all the images all\nthe prices all the text who the sellers\nare and you'll notice on this website\nthere are a bunch of repeating tiles and\neach tile kind of has some items inside\nof it so if we take a look at the HTML\ncode you'll notice that there are a\nbunch of blocks and they're all called\nthe same thing so although they're all\ndivs and they have a class tile call x\n12 x l6 and so the tile is what we're\nmostly concerned about the other classes\nare basically showing how it would\nappear in in kind of like a mobile view\nso how many tiles would you have in a\nrow and so what we'll notice when we\ntake a look at this div is that each of\nthese tiles actually has the same\nunderlying code underneath it but to the\nthe actual text or image link is\ndifferent but the markup is the same so\nwe're going to use that with Python to\nkind of extract out the data so if we\ntake a look under this tile there's a\ncard\nand then we have a link block which is a\ntag and so the link has a image\nunderneath it so if you if you click\nthat link it actually goes to e click\nthe link or the top half or the image it\ngoes to the individual page of the\nlisting so we'll go to this diesel jeans\nlisting and so that's just one block and\nthen you have another items detail block\nwhich is denoted with the div and then\nyou have conditions and then you have\nthe price and the brand as well and\nyou'll notice that these each have these\nweird sometimes named classes fw - bolin\nand then here you have some better thing\na better named class which is tile\ndetails pipe size and so these classes\nare the same if we take a look at the\nnext tile and so that's that's what\nwe'll do if we take a look at for the\nnext tile you'll notice that the classes\nare the same\nand we're going to use that to extract\nout the data so once we figure out how\nto scrape and extract the data from one\ntile we will repeat it on all the tiles\nlet's dive into the code\nwe're going to scrape down the denim\nlisting so the first thing we have to do\nis use the request package we're going\nto import get from that and we'll have\nthe URL and what we're gonna do is we're\ngonna run get on that URL and it's gonna\nreturn a response object the response\nobject has a status and a text and the\nstatus is kind of like what happened did\nyou get the page or not and the text is\nthe actual raw HTML text and so we're\ngoing to just print out a slice of the\nfirst 500 characters now it's a large\nstring so don't print it all out because\nit'll be hundreds and hundreds of lines\nso you can see this is just kind of the\nHTML page it has the has kind of the\ntitle their diesel jeans for men\nPoshmark and then of course all the rest\nof them is there as well we're going to\nuse the package twelve beautifulsoup and\nthat is meant for parsing raw HTML and\nwhat we do is we give it the HTML string\nand then we feed it a parser and then it\nwill return a beautiful soup object and\nwe can run very specific methods on that\nbeautiful soup object\nso there are several methods what we're\ngonna do is we're actually gonna do is\nto find all so if you notice when we go\nback to the top and look at all the\ntiles you'll notice that all the tiles\nhave a class tile and that's only for\nthese elements on the page do they have\nthat class tile so what we're gonna do\nis we're gonna research and find all the\nelements that have tile and that will\ngive us our clothing containers so on\nthe super object we run the method find\nall and we give it the element so the\ndiv element and then we give it the\nclass tile and remember you have to have\nclass underscore equals and that's\nbecause class is of course a protected\nkeyword in Python so you can never have\nyou can never just type in class without\nactually defining a class and here we go\nwe get a result set which is just a type\nof beautifulsoup object and then just\nlike a combination of several beautiful\nsleep objects and then we have the lens\nwhich is 48 which makes sense because we\nget 48 listings when the page loads\nso we can take a look at the first aisle\nbecause it's just a result set which is\nsimilar to a list we can extract out the\nfirst element and then print it now\nunless you're familiar with web\ndevelopment this is gonna look like a\nlot of gibberish it's very hard to read\nand see what's going on what we can do\nis we can actually run prettify on that\ntext and what that will do is actually\nindent everything properly so we can\nread it better but still it's very hard\nto read you you all must notice some of\nthe blocks kind of breaking out you have\nlike the top link block which has the\nimage in it then you have like the item\ndetails which has the title and and so\nforth\nso now all we want to do is extract out\nthe individual values\nin order to extract out the values what\nwe need to do is find each element that\nwe want that has have either the title\nor the price of the brand and then and\nthen extract out the text so what we're\ngoing to do is we're going to take our\ntile and we're gonna do find the a tag\nthe link tag that has a class tile title\nso we have one H egg at the beginning\nthat has kind of the link to the\nindividual page and the image and so\nthat's useful we definitely want that so\nfor example it takes you to the page\nbut we're really interested in the tile\ntitle so that is actually the second a\ntag within item details\nit's an item details and a title\ncondition container and then here we\nhave this the a tag and has the tile\ntitle and so when we find that element\ndo we see here again this has the link\nto the individual and the title and so\nwhat we want to do is we find that a tag\nand then we want that the one\nspecifically that has the class tile\ntitle if we look for other eight tags\nwe're getting other HTML elements\nso when we print it out we get this\nwhole block of text and\nthis is you know this is what we wanted\nbut we really want some specific\ninformation from there so it has the the\nlink to the individual page but really\nwhat we want is the the title and so\nwhat we can do is we can run we can run\nthis method on that object so what we do\nwhat we would want to do is just run the\nsame code and then and then just modify\nit so what we're gonna do is beautiful\nsoup has this method called get text\nit's it's just built-in and what it does\nis it just gets the underlying text in\nbetween the a tag opening which is that\nwhole part that's the the you know HTML\ntags I usually open and close some are\nself closing but the majority open and\nclosed so we have a and then we have in\nthe middle of the text and then the\no'clock closing with the backslash so\nwhat this does is when we do get text we\nwe get the text in between a tag\nand so when we print it out we get the\ntext now we don't have any of the extra\nHTML we just get that you'll notice it\nlooks a bit weird we have all this space\nthere's like a new line and there's all\nthis white space and really that that\nhappens when HTML pages and elements are\ndynamically generated so you can see\neven the space appears in the in the\ncode right there and so what we can do\nis we can we can actually pass a\nparameter strip equals true and that's\ngonna strip all the whitespace and then\nwe really just repeat the same logic on\nthe other elements so we can find the\nspan with the class fw - - bold which\ncorresponds to the span that stores the\nthe price\nactually funny story I made this\ntutorial two weeks ago and then just\nchecked it the night before and this\nclass had actually changed and I had to\nfix it and changed his name and I had to\nfix it to make sure the code was working\nbefore I recorded this\nso just notice I'm just kind of\nhighlighting with HTML that it has it\nhas it like a tree structure and so\nsometimes if you don't have like\nwell-defined classes or they're they're\njust gibberish what you can do is you\ncan actually just try to find like a\nparent element or a top-level element\nand then you can find children and\nsibling elements and kind of traverse\nthe tree that's what they call it so\nhere we're just gonna find the span\nagain with the class fw - - bowles and\nthat's going to get our span element and\nif we just do the same logic get text a\nstrip equals true we get out the price\nand then we can do the same thing for\nsize we can get the a tag with the class\ntile details pipe size\nand then we get size 36 and we can do\nthe same thing with brand and we get\ndiesel the the last two will be a little\ndifferent we're going to be looking at\nthe link and so with link we can we can\njust grab the link with a glass tile\ntitle but then what we're gonna do is we\nactually want to get one of its\nattributes and so if you remember this\nbig block of code with the a tag it has\na bunch of attributes so it has the href\nattribute and all these other ones and\nhref is basically stands for a link so a\nreference and so that is they reference\nto the individual product page and so\nthat's the attribute we want to get to\nthe value for you could almost think of\nit like a dictionary is a bunch of key\nvalue pairs right key is the href the\nvalue is that string\nand so if we just get the href you can\nsee we get this string value and you can\neven get the class or any other other\nkind of attribute the one problem with\nthis string value is that it's it's not\ncomplete right it's it's the trailing\nstrength it's the trailing URL after you\nhave Poshmark com so we'd actually want\nto do this just add wwhy calm before\nthat to get the actual working link and\nthen we can really just do the same\nthing with the image we want to get the\nimage URL in case you want to store the\nimage later so we can get we can find to\nthe image there's only one image tag a\nnested under there and then we want to\nget this source attribute and so we can\nget the value for that\nthe next step we want to do is we can\njust kind of print out a summary of our\ndata the problem is that when you scrape\ninformation from a website everything is\na string value so all these are strings\nand and what we really want to do is we\nwant to convert the price to just an int\nand then the same with a size right we\njust want to say area we have a the\nprice is 55 because we will know it's in\ndollars and then the size is 36 and and\nwe'll kind of just know that's 36 waist\nsize inches for men's like men's jeans\nbecause we're looking at men's jeans\nso we're gonna take the first price\nvariable and then we're just going to\nuse a basic string manipulation to\nreplace out the unwanted characters you\ncan use something more complicated like\nregular expressions but I think since\nour use case is very simple it makes\nsense just to use a string to replace\nand so what we're gonna do is we replace\nthe dollar sign with a empty string so\nessentially we will delete the dollar\nsign and so now we get 55 but it's still\nof type string so what we want to do is\nwrap it into a int type conversion so if\nyou do that you will actually get to\ninteger 55 and the reason you can't just\ndo that\nyou can't just into first prices because\nit's unable to kind of convert the\nstring like the dollars the dollar sign\nstring that makes it the cause of some\nissues now we can do the same exact\nthing with size we'll just replace the\nsize colon space with an empty space so\nessentially deleting it and then we can\nprint out the type and the value\nnow one thing you'll notice with the\nimage link is that you can actually see\nthe posted date so this product was\nposted on 20/20 May 10th and we can do\nis we actually can extract that and find\nout how long an item has been listed so\nwe could we could kind of subtract out\nthe difference between the posted date\nand today's date so here we can we can\nkind of find the value 20/20 and what\nthat really does is it fine this is a\nstring so we can we can do string\nindexing so we'll find the index value\nso when does when does that start so it\nstarts at the 43rd character and then\nour 44th if you're indexing from zero\nand then all the dates are the same\nright it's it's ten characters long you\nhave you have the year you have the\nmonth and you have the day and then the\nslash is in between and so you can\ntechnophile the beginning and end and\njust extract that out because you know\nall the date strings will be the same\nfor all the image lengths and so you\njust do a string slice and just extract\nout that substring\nand then we're going to bring in that\ndate you tell parser package now this is\nis gonna do some magic underneath but\nessentially you can parse a bunch of\ndifferent string dates and then return a\nPython date object so we really just\njust really import parse and then and\nthen just feed it and then it finds out\nthat what the date is and if you want to\nfind the difference between days you can\nactually use a day time to find out\ntoday's date or right now as date and\nthen it will find the exact day and in\nseconds and then we can kind of subtract\nout the difference between the days and\nand take the absolute value of the\nnumber of days and we get one and so\nyou're always going to get a positive\nnumber because we did the absolute value\nbut also because you kind of have\nseconds and minutes that happen\ndifference and then again if you're\ndoing this in a professional work show\nworkflow you'll have to make sure you\nhave like the time zones and everything\nbut but normally what you'll do is\nyou'll scrape the raw data store the raw\ndata and kind of a flat file like CSV or\nJSON then you will type format the data\nand then you will extract out new\nfeatures so you'll want to kind of silo\neach process so you can create different\nversions of the data\nand then we'll just take a few minute\nbreak the next part of the notebook is\nreally showing how to refactor code and\nand create functions and so the code\nbefore was just really procedural code\nkind of a string string code what you\nwould call just kind of writin what\ncomes up and then just trying to put it\nall together and make sure it works but\nwhat you want to do is really create\nfunctions and module has it and so here\nare some good guidelines just like\nsensible names single responsibility\nincludes a doc string returns a value\nand it's not longer than 50 lines and I\ndon't really follow this exactly in the\nfunctions I've created but just to give\nyou an example of what some better\nbetter organized code would look like\nand just kind of each function is\nresponsible for one thing you know\nextracting the title extracting the\nprice extracting the brand and so forth\nand normally you probably wouldn't have\ntwo things for example like in this\nprice function I am getting the price\nand then I'm type converting and\nformatting it you'd you'd actually\nseparate that into two functions so you\ncan kind of have a single responsibility\nbut that's more just kind of you know\njust some software engineering tips and\nthen here I have another function called\ncombined data and what this does is it\nhas a bunch of try and accept blocks and\nthen it returns an object with all the\nvalues but with web scraping sometimes\nthere is no values on the webpage right\nlike a title could be missing a size\ncould be missing it might not have a\nsize it could be like unisex sizing or\nwhatever and that's why we have to have\ntry and accept blah except blocks\nbecause we need to return an empty\nstring or empty value in a case it\ndoesn't find anything because we don't\nwant our code just to break and crash in\nthe middle of a loop and so that's why\nit looks really ugly but but that's just\nwhat we need to do in order to ensure\nthat ensure that the code runs and\ndoesn't kind of break several times\nand so once we have those values you\nknow title or price size brand and all\nthose values from the tile you know\nbasically take a tile and then we we\ninsert that in there and then run all\nthese kind of nested functions we just\nreturned in this object just a\ndictionary key value pairs of the\nprivate all the values and so let's\nlet's try to extract out all the tiles\non an initial page we're going to\ndownload the page we're going to create\na beautiful super object we're going to\nextract out all the tiles and then I and\nthen I have kind of this list\ncomprehension which is really just an\neasy way to do a for loop while\nappending to a list I can you can kind\nof just like break out what that looks\nlike in case you're not familiar so if\nwe have all the tiles we have a list of\nall the HTML tiles this is what a all\nthis comprehension will look like next\nbasically we want to run a function on\nevery single tile and return a\ndictionary of the values what we do is\nfor each tile in item tiles we would run\nthe function combined data on the tile\nand we would assign that to a variable\nit can be it could be anything and then\nwhat we would want to do is we'd have\nsome like item objects and we depend\nthat so you'd also have to create that\nitem objects it would be an empty string\nand really what a list comprehension\ndoes is just this is just a very common\nprocedure that you have to do in Python\nencoding and so it just tracks that to\none line and this is not something you\ncan do in every language it's it's\nsomething that only exists in Python a\ncouple of other languages so but it's\njust a nifty trick all right so we have\n48 tiles that means if we run this we\nshould have 48 item objects and then if\nwe print we can take a look at each one\nso it's a bit hard to read so you can\nbring in the package P print or pretty\nprint and\nit looks better\nkind of the same as prettify just gives\nyou the indentation and spacing\noh yeah so one thing to notice is you're\nonly get 48 items because you'll notice\nhere as I'm scrolling it adds more items\nto the page using JavaScript\num but we can only get 48 because we're\ndoing a programmatic request and if you\nreally want to get all the paid items\nthat load you you really have to use\nanother package that that lets you use\nheadless browsers and what that does is\nit creates like a ghost instance of\nFirefox or Chrome and actually browses\nthe page and then downloads the the HTML\nand so in the git repo that I've linked\nthere is an advanced notebook that kind\nof shows you how to use it in advance a\nheadless browser it it kind of requires\na bit of configuration so it might not\nbe easy but it might not be easy to run\nit on your local computer\nall right so why don't we look at a\nbunch of brands let's extract out a\nbunch of other men's denim brands and\nreally what we can do is we can just run\nthat same block of code just looping\nthrough a list of brands and so if I\npenned this to this like master store\nwhat we're gonna get is the store is\ngonna be aligned thefor because we have\nfour brands and then each item within\nthe store is gonna have 48 item objects\nso it's really gonna be a list of lists\nright for and then each for as 48 and we\ndon't really want that because we really\njust want 4 times 48 right like 196 or\nyes or maybe a hundred ninety-two sorry\nabout Malthus my math is off but what we\nreally want to do is just extend how the\nlists and and so instead of append we do\nextend and that will just add and add\nand add to the same master list so I\nthink oh yeah 192 right ok there we go\nand then we'll have a length of the\nfirst item as 8 and that's really just\nan 8 8 key value pairs from the object\nso just gonna run through this last\nsection really quickly if you if you're\nfamiliar with pandas or not pandas is\nkind of like microcell for Python if you\nwill it allows you to manipulate and\norganize data in tabular form and so we\ncan kind of create a new column with the\nlength of the title we can look at a\npreview of the data we can kind of take\na subset of numeric data I'm just kind\nof like the price size difference length\nso then we can the reason why I just\nwant the numeric data so I can I can do\nsome kind of analysis on that by just\nlooking at like the mean and the\noutliers and so forth\nso you'll notice the kind of difference\nthe differences is the days right we\nhave some that were listen for two days\nand some that were listed for like a\ncouple years and so I guess something\nwas just not popular too expensive or\neven if you're actually a Poshmark user\nyou'll know this\nsome people just kind of check out right\nthey they kind of list a product and\nthen and then they they don't ever check\ntheir account\nso you notice some brands are listed the\nat median is longer and the price is\nobviously different for different brands\nyou can bring in matplotlib to visualize\nsome of these things like the kind of\ndistribution of prices and you'll notice\nit's more pronounced with the individual\nbrands but you kind of have like two\npeaks you have like one center around 20\n30 40 and then one at the end and so\nreally what that is is again this is\nlike another kind of data science domain\nexpertise or if you use Poshmark people\ncan list new and used objects or items\nso for each brand you'll see two\ngroupings and one grouping is the used\nitems and the other grouping is like\ncompletely like totally new items or\nslightly slightly used or like new\nwithout tagged this type of thing and so\nso something definitely if we were to\nredo this analysis is we definitely want\nto extract out whether yes you see kind\nof like the separate Peaks or separate\ngroupings and so one thing you want to\ndo is extract out new and used items I\ncould have kind of like a boolean value\nand then in another column\nand we can also look at just like the\ndifference the days listed as well as a\nwhole and then and then kind of by brand\nand you'll see some we can you can kind\nof look at which brand has the longest\none so it looks like naked famous takes\nthe cake it's it's more of a niche brand\nBasso tarik so uh yeah I make sense that\nsome items were just like a little out\nthere\nso there's obviously more analysis you\ncan do I kind of did a very rudimentary\nexploratory data analysis but it was it\nwas useful you know this just don't land\nup the titles which doesn't really show\nanything so feel free to this was like a\nlive webinar so there's questions but\nthere's a feedback form in the notebook\nand and you know you can send me a\nmessage on meetup if you have any\nquestions or concerns or just anything\nabout scraping I'm not like a\nprofessional I just kind of do it as a\nhobby so I might not be able to answer\nall your questions but I'll try my best\nand stay tuned for more events from dat\numbrella and pilotis in the future", "idn": "03", "video_url": "https://youtu.be/0L1uM_18TTA", "title_kw": "webscraping", "meta_json": "03.json", "audio_track": "03_0L1uM_18TTA.mp4", "audio_text": "03_0L1uM_18TTA.txt", "has_transcript": true, "status": "", "notes": "These are tests notes."}